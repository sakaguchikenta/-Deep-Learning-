{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.48618104  0.21551717 -0.57530677]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[1,0,0,0,0,0,0,]])\n",
    "w = np.random.randn(7,3)\n",
    "h = np.dot(c,w)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "c0 = np.array([[1,0,0,0,0,0,0,]])\n",
    "c1 = np.array([[0,0,1,0,0,0,0]])\n",
    "\n",
    "W_in = np.random.randn(7,3)\n",
    "W_out = np.random.randn(3,7)\n",
    "\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "def create_contexts_target(corpus, window_size =1):\n",
    "    target = corpus[window_size: -window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size +1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "        \n",
    "    return np.array(contexts), np.array(target)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size =1)\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V,H = vocab_size, hidden_size\n",
    "        \n",
    "        W_in = 0.01 * np.random.randn(V,H).astype('f')\n",
    "        W_out = 0.01*np.random.randn(h,V).astype('f')\n",
    "        \n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        self.word_vecs =W_in\n",
    "        \n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:,0])\n",
    "        h1 = self.in_layer1.forward(contexts[:,1])\n",
    "        h = (h0 + h1)*0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss  = self.loss_layer.forward(score,target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_cbow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-16911e6dd62c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimple_cbow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleCBOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_contexts_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simple_cbow'"
     ]
    }
   ],
   "source": [
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam \n",
    "from simple_cbow import SimpleCBOW\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vacab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self,W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "    def forward(self, idx):\n",
    "            W, = self.params\n",
    "            self.idx = idx\n",
    "            out = W[idx]\n",
    "            return out\n",
    "    def backward(self, dout):\n",
    "            dw, = self.grads\n",
    "            dw[...] = 0\n",
    "           \n",
    "            for i , word_id in enumerate(self.idx):\n",
    "                dw[word_id] += dout[i]\n",
    "            \n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "    def forward(self, h ,idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W * h, axis=1)\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0],1)\n",
    "        \n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power = 0.75, sample_size = 5):\n",
    "        self.sample_size = sample_size\n",
    "        self.sampler = UnigramSampler(courpus, power, sample_size)\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size +1)]\n",
    "        self.emped_dot_layers = [EmbeddingDot(W) for _ in range(sample_size +1)]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    \n",
    "    def forward(self, h, target):\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_nagetive_sample(target)\n",
    "        \n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = np.ones(batch_size, dtype=np.int32)\n",
    "        loss = self.loss_layers[0].forward(score, correct_label)\n",
    "        \n",
    "        negative_label = np.zeros(batch_size, dtype=np.int32)\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:,i]\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_laers[1 + i].forward(score, negative_label)\n",
    "        return loss   \n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "            dh = 0\n",
    "            for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
    "                dscore = l0.backward(dout)\n",
    "                dh += l1.backward(dscore)\n",
    "            return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import Embedding\n",
    "from ch04.negative_sampling_layer import NegativeSamplingLoss\n",
    "\n",
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H  = vocab_size, hidden_size\n",
    "        \n",
    "        W_in = 0.01 * np.random.randn(V,H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        \n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out,corpus, power=0.75, sample_size=5)\n",
    "        \n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        self.word_vecs =W_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, contexts, target):\n",
    "    h = 0\n",
    "    for i, layer in enumerate(self.in_layers):\n",
    "        h += layer.forward(contexts[:, i])\n",
    "    h *= 1 /len(self.in_layers)\n",
    "    loss = self.ns_loss.forward(h,target)\n",
    "    return loss\n",
    "\n",
    "def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout*= 1/ len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "              layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "| epoch 1 |  iter 1 / 9295 | time 0[s] | loss 4.16\n",
      "| epoch 1 |  iter 21 / 9295 | time 0[s] | loss 4.16\n",
      "| epoch 1 |  iter 41 / 9295 | time 1[s] | loss 4.15\n",
      "| epoch 1 |  iter 61 / 9295 | time 2[s] | loss 4.12\n",
      "| epoch 1 |  iter 81 / 9295 | time 2[s] | loss 4.05\n",
      "| epoch 1 |  iter 101 / 9295 | time 3[s] | loss 3.93\n",
      "| epoch 1 |  iter 121 / 9295 | time 3[s] | loss 3.78\n",
      "| epoch 1 |  iter 141 / 9295 | time 4[s] | loss 3.63\n",
      "| epoch 1 |  iter 161 / 9295 | time 5[s] | loss 3.48\n",
      "| epoch 1 |  iter 181 / 9295 | time 5[s] | loss 3.36\n",
      "| epoch 1 |  iter 201 / 9295 | time 6[s] | loss 3.26\n",
      "| epoch 1 |  iter 221 / 9295 | time 7[s] | loss 3.14\n",
      "| epoch 1 |  iter 241 / 9295 | time 7[s] | loss 3.08\n",
      "| epoch 1 |  iter 261 / 9295 | time 8[s] | loss 3.00\n",
      "| epoch 1 |  iter 281 / 9295 | time 8[s] | loss 2.95\n",
      "| epoch 1 |  iter 301 / 9295 | time 9[s] | loss 2.93\n",
      "| epoch 1 |  iter 321 / 9295 | time 10[s] | loss 2.87\n",
      "| epoch 1 |  iter 341 / 9295 | time 10[s] | loss 2.85\n",
      "| epoch 1 |  iter 361 / 9295 | time 11[s] | loss 2.81\n",
      "| epoch 1 |  iter 381 / 9295 | time 12[s] | loss 2.78\n",
      "| epoch 1 |  iter 401 / 9295 | time 12[s] | loss 2.75\n",
      "| epoch 1 |  iter 421 / 9295 | time 13[s] | loss 2.75\n",
      "| epoch 1 |  iter 441 / 9295 | time 14[s] | loss 2.72\n",
      "| epoch 1 |  iter 461 / 9295 | time 14[s] | loss 2.71\n",
      "| epoch 1 |  iter 481 / 9295 | time 15[s] | loss 2.69\n",
      "| epoch 1 |  iter 501 / 9295 | time 15[s] | loss 2.67\n",
      "| epoch 1 |  iter 521 / 9295 | time 16[s] | loss 2.68\n",
      "| epoch 1 |  iter 541 / 9295 | time 17[s] | loss 2.65\n",
      "| epoch 1 |  iter 561 / 9295 | time 17[s] | loss 2.68\n",
      "| epoch 1 |  iter 581 / 9295 | time 18[s] | loss 2.66\n",
      "| epoch 1 |  iter 601 / 9295 | time 19[s] | loss 2.66\n",
      "| epoch 1 |  iter 621 / 9295 | time 19[s] | loss 2.64\n",
      "| epoch 1 |  iter 641 / 9295 | time 20[s] | loss 2.66\n",
      "| epoch 1 |  iter 661 / 9295 | time 20[s] | loss 2.63\n",
      "| epoch 1 |  iter 681 / 9295 | time 21[s] | loss 2.61\n",
      "| epoch 1 |  iter 701 / 9295 | time 22[s] | loss 2.61\n",
      "| epoch 1 |  iter 721 / 9295 | time 22[s] | loss 2.61\n",
      "| epoch 1 |  iter 741 / 9295 | time 23[s] | loss 2.62\n",
      "| epoch 1 |  iter 761 / 9295 | time 24[s] | loss 2.59\n",
      "| epoch 1 |  iter 781 / 9295 | time 24[s] | loss 2.59\n",
      "| epoch 1 |  iter 801 / 9295 | time 25[s] | loss 2.61\n",
      "| epoch 1 |  iter 821 / 9295 | time 25[s] | loss 2.56\n",
      "| epoch 1 |  iter 841 / 9295 | time 26[s] | loss 2.59\n",
      "| epoch 1 |  iter 861 / 9295 | time 27[s] | loss 2.58\n",
      "| epoch 1 |  iter 881 / 9295 | time 27[s] | loss 2.58\n",
      "| epoch 1 |  iter 901 / 9295 | time 28[s] | loss 2.60\n",
      "| epoch 1 |  iter 921 / 9295 | time 29[s] | loss 2.56\n",
      "| epoch 1 |  iter 941 / 9295 | time 29[s] | loss 2.58\n",
      "| epoch 1 |  iter 961 / 9295 | time 30[s] | loss 2.56\n",
      "| epoch 1 |  iter 981 / 9295 | time 31[s] | loss 2.56\n",
      "| epoch 1 |  iter 1001 / 9295 | time 31[s] | loss 2.56\n",
      "| epoch 1 |  iter 1021 / 9295 | time 32[s] | loss 2.57\n",
      "| epoch 1 |  iter 1041 / 9295 | time 32[s] | loss 2.54\n",
      "| epoch 1 |  iter 1061 / 9295 | time 33[s] | loss 2.56\n",
      "| epoch 1 |  iter 1081 / 9295 | time 34[s] | loss 2.53\n",
      "| epoch 1 |  iter 1101 / 9295 | time 34[s] | loss 2.55\n",
      "| epoch 1 |  iter 1121 / 9295 | time 35[s] | loss 2.55\n",
      "| epoch 1 |  iter 1141 / 9295 | time 36[s] | loss 2.53\n",
      "| epoch 1 |  iter 1161 / 9295 | time 36[s] | loss 2.58\n",
      "| epoch 1 |  iter 1181 / 9295 | time 37[s] | loss 2.54\n",
      "| epoch 1 |  iter 1201 / 9295 | time 37[s] | loss 2.54\n",
      "| epoch 1 |  iter 1221 / 9295 | time 38[s] | loss 2.55\n",
      "| epoch 1 |  iter 1241 / 9295 | time 39[s] | loss 2.52\n",
      "| epoch 1 |  iter 1261 / 9295 | time 39[s] | loss 2.53\n",
      "| epoch 1 |  iter 1281 / 9295 | time 40[s] | loss 2.54\n",
      "| epoch 1 |  iter 1301 / 9295 | time 41[s] | loss 2.52\n",
      "| epoch 1 |  iter 1321 / 9295 | time 41[s] | loss 2.56\n",
      "| epoch 1 |  iter 1341 / 9295 | time 42[s] | loss 2.55\n",
      "| epoch 1 |  iter 1361 / 9295 | time 43[s] | loss 2.52\n",
      "| epoch 1 |  iter 1381 / 9295 | time 43[s] | loss 2.53\n",
      "| epoch 1 |  iter 1401 / 9295 | time 44[s] | loss 2.53\n",
      "| epoch 1 |  iter 1421 / 9295 | time 44[s] | loss 2.52\n",
      "| epoch 1 |  iter 1441 / 9295 | time 45[s] | loss 2.53\n",
      "| epoch 1 |  iter 1461 / 9295 | time 46[s] | loss 2.51\n",
      "| epoch 1 |  iter 1481 / 9295 | time 46[s] | loss 2.53\n",
      "| epoch 1 |  iter 1501 / 9295 | time 47[s] | loss 2.48\n",
      "| epoch 1 |  iter 1521 / 9295 | time 48[s] | loss 2.51\n",
      "| epoch 1 |  iter 1541 / 9295 | time 48[s] | loss 2.50\n",
      "| epoch 1 |  iter 1561 / 9295 | time 49[s] | loss 2.51\n",
      "| epoch 1 |  iter 1581 / 9295 | time 49[s] | loss 2.52\n",
      "| epoch 1 |  iter 1601 / 9295 | time 50[s] | loss 2.51\n",
      "| epoch 1 |  iter 1621 / 9295 | time 51[s] | loss 2.51\n",
      "| epoch 1 |  iter 1641 / 9295 | time 51[s] | loss 2.49\n",
      "| epoch 1 |  iter 1661 / 9295 | time 52[s] | loss 2.53\n",
      "| epoch 1 |  iter 1681 / 9295 | time 53[s] | loss 2.53\n",
      "| epoch 1 |  iter 1701 / 9295 | time 53[s] | loss 2.51\n",
      "| epoch 1 |  iter 1721 / 9295 | time 54[s] | loss 2.48\n",
      "| epoch 1 |  iter 1741 / 9295 | time 55[s] | loss 2.52\n",
      "| epoch 1 |  iter 1761 / 9295 | time 55[s] | loss 2.47\n",
      "| epoch 1 |  iter 1781 / 9295 | time 56[s] | loss 2.50\n",
      "| epoch 1 |  iter 1801 / 9295 | time 57[s] | loss 2.52\n",
      "| epoch 1 |  iter 1821 / 9295 | time 57[s] | loss 2.50\n",
      "| epoch 1 |  iter 1841 / 9295 | time 58[s] | loss 2.50\n",
      "| epoch 1 |  iter 1861 / 9295 | time 58[s] | loss 2.52\n",
      "| epoch 1 |  iter 1881 / 9295 | time 59[s] | loss 2.50\n",
      "| epoch 1 |  iter 1901 / 9295 | time 60[s] | loss 2.50\n",
      "| epoch 1 |  iter 1921 / 9295 | time 60[s] | loss 2.48\n",
      "| epoch 1 |  iter 1941 / 9295 | time 61[s] | loss 2.50\n",
      "| epoch 1 |  iter 1961 / 9295 | time 62[s] | loss 2.49\n",
      "| epoch 1 |  iter 1981 / 9295 | time 62[s] | loss 2.49\n",
      "| epoch 1 |  iter 2001 / 9295 | time 63[s] | loss 2.51\n",
      "| epoch 1 |  iter 2021 / 9295 | time 63[s] | loss 2.50\n",
      "| epoch 1 |  iter 2041 / 9295 | time 64[s] | loss 2.48\n",
      "| epoch 1 |  iter 2061 / 9295 | time 65[s] | loss 2.46\n",
      "| epoch 1 |  iter 2081 / 9295 | time 65[s] | loss 2.47\n",
      "| epoch 1 |  iter 2101 / 9295 | time 66[s] | loss 2.47\n",
      "| epoch 1 |  iter 2121 / 9295 | time 67[s] | loss 2.48\n",
      "| epoch 1 |  iter 2141 / 9295 | time 67[s] | loss 2.48\n",
      "| epoch 1 |  iter 2161 / 9295 | time 68[s] | loss 2.45\n",
      "| epoch 1 |  iter 2181 / 9295 | time 69[s] | loss 2.50\n",
      "| epoch 1 |  iter 2201 / 9295 | time 69[s] | loss 2.49\n",
      "| epoch 1 |  iter 2221 / 9295 | time 70[s] | loss 2.50\n",
      "| epoch 1 |  iter 2241 / 9295 | time 70[s] | loss 2.51\n",
      "| epoch 1 |  iter 2261 / 9295 | time 71[s] | loss 2.49\n",
      "| epoch 1 |  iter 2281 / 9295 | time 72[s] | loss 2.49\n",
      "| epoch 1 |  iter 2301 / 9295 | time 72[s] | loss 2.46\n",
      "| epoch 1 |  iter 2321 / 9295 | time 73[s] | loss 2.49\n",
      "| epoch 1 |  iter 2341 / 9295 | time 74[s] | loss 2.49\n",
      "| epoch 1 |  iter 2361 / 9295 | time 74[s] | loss 2.47\n",
      "| epoch 1 |  iter 2381 / 9295 | time 75[s] | loss 2.50\n",
      "| epoch 1 |  iter 2401 / 9295 | time 76[s] | loss 2.50\n",
      "| epoch 1 |  iter 2421 / 9295 | time 76[s] | loss 2.46\n",
      "| epoch 1 |  iter 2441 / 9295 | time 77[s] | loss 2.49\n",
      "| epoch 1 |  iter 2461 / 9295 | time 77[s] | loss 2.49\n",
      "| epoch 1 |  iter 2481 / 9295 | time 78[s] | loss 2.46\n",
      "| epoch 1 |  iter 2501 / 9295 | time 79[s] | loss 2.47\n",
      "| epoch 1 |  iter 2521 / 9295 | time 79[s] | loss 2.48\n",
      "| epoch 1 |  iter 2541 / 9295 | time 80[s] | loss 2.46\n",
      "| epoch 1 |  iter 2561 / 9295 | time 81[s] | loss 2.47\n",
      "| epoch 1 |  iter 2581 / 9295 | time 81[s] | loss 2.46\n",
      "| epoch 1 |  iter 2601 / 9295 | time 82[s] | loss 2.48\n",
      "| epoch 1 |  iter 2621 / 9295 | time 82[s] | loss 2.45\n",
      "| epoch 1 |  iter 2641 / 9295 | time 83[s] | loss 2.47\n",
      "| epoch 1 |  iter 2661 / 9295 | time 84[s] | loss 2.44\n",
      "| epoch 1 |  iter 2681 / 9295 | time 84[s] | loss 2.46\n",
      "| epoch 1 |  iter 2701 / 9295 | time 85[s] | loss 2.48\n",
      "| epoch 1 |  iter 2721 / 9295 | time 86[s] | loss 2.46\n",
      "| epoch 1 |  iter 2741 / 9295 | time 86[s] | loss 2.46\n",
      "| epoch 1 |  iter 2761 / 9295 | time 87[s] | loss 2.49\n",
      "| epoch 1 |  iter 2781 / 9295 | time 88[s] | loss 2.45\n",
      "| epoch 1 |  iter 2801 / 9295 | time 88[s] | loss 2.43\n",
      "| epoch 1 |  iter 2821 / 9295 | time 89[s] | loss 2.46\n",
      "| epoch 1 |  iter 2841 / 9295 | time 89[s] | loss 2.46\n",
      "| epoch 1 |  iter 2861 / 9295 | time 90[s] | loss 2.48\n",
      "| epoch 1 |  iter 2881 / 9295 | time 91[s] | loss 2.42\n",
      "| epoch 1 |  iter 2901 / 9295 | time 91[s] | loss 2.47\n",
      "| epoch 1 |  iter 2921 / 9295 | time 92[s] | loss 2.47\n",
      "| epoch 1 |  iter 2941 / 9295 | time 93[s] | loss 2.47\n",
      "| epoch 1 |  iter 2961 / 9295 | time 93[s] | loss 2.46\n",
      "| epoch 1 |  iter 2981 / 9295 | time 94[s] | loss 2.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 3001 / 9295 | time 94[s] | loss 2.46\n",
      "| epoch 1 |  iter 3021 / 9295 | time 95[s] | loss 2.47\n",
      "| epoch 1 |  iter 3041 / 9295 | time 96[s] | loss 2.44\n",
      "| epoch 1 |  iter 3061 / 9295 | time 96[s] | loss 2.45\n",
      "| epoch 1 |  iter 3081 / 9295 | time 97[s] | loss 2.45\n",
      "| epoch 1 |  iter 3101 / 9295 | time 98[s] | loss 2.40\n",
      "| epoch 1 |  iter 3121 / 9295 | time 98[s] | loss 2.41\n",
      "| epoch 1 |  iter 3141 / 9295 | time 99[s] | loss 2.42\n",
      "| epoch 1 |  iter 3161 / 9295 | time 100[s] | loss 2.45\n",
      "| epoch 1 |  iter 3181 / 9295 | time 100[s] | loss 2.44\n",
      "| epoch 1 |  iter 3201 / 9295 | time 101[s] | loss 2.42\n",
      "| epoch 1 |  iter 3221 / 9295 | time 101[s] | loss 2.41\n",
      "| epoch 1 |  iter 3241 / 9295 | time 102[s] | loss 2.45\n",
      "| epoch 1 |  iter 3261 / 9295 | time 103[s] | loss 2.41\n",
      "| epoch 1 |  iter 3281 / 9295 | time 103[s] | loss 2.45\n",
      "| epoch 1 |  iter 3301 / 9295 | time 104[s] | loss 2.43\n",
      "| epoch 1 |  iter 3321 / 9295 | time 105[s] | loss 2.46\n",
      "| epoch 1 |  iter 3341 / 9295 | time 105[s] | loss 2.44\n",
      "| epoch 1 |  iter 3361 / 9295 | time 106[s] | loss 2.42\n",
      "| epoch 1 |  iter 3381 / 9295 | time 106[s] | loss 2.45\n",
      "| epoch 1 |  iter 3401 / 9295 | time 107[s] | loss 2.41\n",
      "| epoch 1 |  iter 3421 / 9295 | time 108[s] | loss 2.42\n",
      "| epoch 1 |  iter 3441 / 9295 | time 108[s] | loss 2.42\n",
      "| epoch 1 |  iter 3461 / 9295 | time 109[s] | loss 2.42\n",
      "| epoch 1 |  iter 3481 / 9295 | time 110[s] | loss 2.44\n",
      "| epoch 1 |  iter 3501 / 9295 | time 110[s] | loss 2.43\n",
      "| epoch 1 |  iter 3521 / 9295 | time 111[s] | loss 2.43\n",
      "| epoch 1 |  iter 3541 / 9295 | time 112[s] | loss 2.41\n",
      "| epoch 1 |  iter 3561 / 9295 | time 112[s] | loss 2.43\n",
      "| epoch 1 |  iter 3581 / 9295 | time 113[s] | loss 2.41\n",
      "| epoch 1 |  iter 3601 / 9295 | time 113[s] | loss 2.42\n",
      "| epoch 1 |  iter 3621 / 9295 | time 114[s] | loss 2.43\n",
      "| epoch 1 |  iter 3641 / 9295 | time 115[s] | loss 2.44\n",
      "| epoch 1 |  iter 3661 / 9295 | time 115[s] | loss 2.41\n",
      "| epoch 1 |  iter 3681 / 9295 | time 116[s] | loss 2.45\n",
      "| epoch 1 |  iter 3701 / 9295 | time 117[s] | loss 2.42\n",
      "| epoch 1 |  iter 3721 / 9295 | time 117[s] | loss 2.42\n",
      "| epoch 1 |  iter 3741 / 9295 | time 118[s] | loss 2.42\n",
      "| epoch 1 |  iter 3761 / 9295 | time 119[s] | loss 2.42\n",
      "| epoch 1 |  iter 3781 / 9295 | time 119[s] | loss 2.41\n",
      "| epoch 1 |  iter 3801 / 9295 | time 120[s] | loss 2.42\n",
      "| epoch 1 |  iter 3821 / 9295 | time 120[s] | loss 2.37\n",
      "| epoch 1 |  iter 3841 / 9295 | time 121[s] | loss 2.41\n",
      "| epoch 1 |  iter 3861 / 9295 | time 122[s] | loss 2.40\n",
      "| epoch 1 |  iter 3881 / 9295 | time 122[s] | loss 2.41\n",
      "| epoch 1 |  iter 3901 / 9295 | time 123[s] | loss 2.43\n",
      "| epoch 1 |  iter 3921 / 9295 | time 124[s] | loss 2.40\n",
      "| epoch 1 |  iter 3941 / 9295 | time 124[s] | loss 2.42\n",
      "| epoch 1 |  iter 3961 / 9295 | time 125[s] | loss 2.38\n",
      "| epoch 1 |  iter 3981 / 9295 | time 125[s] | loss 2.39\n",
      "| epoch 1 |  iter 4001 / 9295 | time 126[s] | loss 2.42\n",
      "| epoch 1 |  iter 4021 / 9295 | time 127[s] | loss 2.40\n",
      "| epoch 1 |  iter 4041 / 9295 | time 127[s] | loss 2.40\n",
      "| epoch 1 |  iter 4061 / 9295 | time 128[s] | loss 2.39\n",
      "| epoch 1 |  iter 4081 / 9295 | time 129[s] | loss 2.38\n",
      "| epoch 1 |  iter 4101 / 9295 | time 129[s] | loss 2.38\n",
      "| epoch 1 |  iter 4121 / 9295 | time 130[s] | loss 2.37\n",
      "| epoch 1 |  iter 4141 / 9295 | time 131[s] | loss 2.41\n",
      "| epoch 1 |  iter 4161 / 9295 | time 131[s] | loss 2.42\n",
      "| epoch 1 |  iter 4181 / 9295 | time 132[s] | loss 2.42\n",
      "| epoch 1 |  iter 4201 / 9295 | time 132[s] | loss 2.37\n",
      "| epoch 1 |  iter 4221 / 9295 | time 133[s] | loss 2.39\n",
      "| epoch 1 |  iter 4241 / 9295 | time 134[s] | loss 2.40\n",
      "| epoch 1 |  iter 4261 / 9295 | time 134[s] | loss 2.39\n",
      "| epoch 1 |  iter 4281 / 9295 | time 135[s] | loss 2.38\n",
      "| epoch 1 |  iter 4301 / 9295 | time 136[s] | loss 2.38\n",
      "| epoch 1 |  iter 4321 / 9295 | time 136[s] | loss 2.39\n",
      "| epoch 1 |  iter 4341 / 9295 | time 137[s] | loss 2.33\n",
      "| epoch 1 |  iter 4361 / 9295 | time 138[s] | loss 2.36\n",
      "| epoch 1 |  iter 4381 / 9295 | time 138[s] | loss 2.37\n",
      "| epoch 1 |  iter 4401 / 9295 | time 139[s] | loss 2.35\n",
      "| epoch 1 |  iter 4421 / 9295 | time 139[s] | loss 2.39\n",
      "| epoch 1 |  iter 4441 / 9295 | time 140[s] | loss 2.38\n",
      "| epoch 1 |  iter 4461 / 9295 | time 141[s] | loss 2.41\n",
      "| epoch 1 |  iter 4481 / 9295 | time 141[s] | loss 2.37\n",
      "| epoch 1 |  iter 4501 / 9295 | time 142[s] | loss 2.37\n",
      "| epoch 1 |  iter 4521 / 9295 | time 143[s] | loss 2.40\n",
      "| epoch 1 |  iter 4541 / 9295 | time 143[s] | loss 2.40\n",
      "| epoch 1 |  iter 4561 / 9295 | time 144[s] | loss 2.37\n",
      "| epoch 1 |  iter 4581 / 9295 | time 144[s] | loss 2.35\n",
      "| epoch 1 |  iter 4601 / 9295 | time 145[s] | loss 2.35\n",
      "| epoch 1 |  iter 4621 / 9295 | time 146[s] | loss 2.38\n",
      "| epoch 1 |  iter 4641 / 9295 | time 146[s] | loss 2.39\n",
      "| epoch 1 |  iter 4661 / 9295 | time 147[s] | loss 2.39\n",
      "| epoch 1 |  iter 4681 / 9295 | time 148[s] | loss 2.36\n",
      "| epoch 1 |  iter 4701 / 9295 | time 148[s] | loss 2.33\n",
      "| epoch 1 |  iter 4721 / 9295 | time 149[s] | loss 2.34\n",
      "| epoch 1 |  iter 4741 / 9295 | time 150[s] | loss 2.37\n",
      "| epoch 1 |  iter 4761 / 9295 | time 150[s] | loss 2.39\n",
      "| epoch 1 |  iter 4781 / 9295 | time 151[s] | loss 2.37\n",
      "| epoch 1 |  iter 4801 / 9295 | time 152[s] | loss 2.39\n",
      "| epoch 1 |  iter 4821 / 9295 | time 152[s] | loss 2.36\n",
      "| epoch 1 |  iter 4841 / 9295 | time 153[s] | loss 2.37\n",
      "| epoch 1 |  iter 4861 / 9295 | time 153[s] | loss 2.36\n",
      "| epoch 1 |  iter 4881 / 9295 | time 154[s] | loss 2.35\n",
      "| epoch 1 |  iter 4901 / 9295 | time 155[s] | loss 2.35\n",
      "| epoch 1 |  iter 4921 / 9295 | time 155[s] | loss 2.35\n",
      "| epoch 1 |  iter 4941 / 9295 | time 156[s] | loss 2.38\n",
      "| epoch 1 |  iter 4961 / 9295 | time 157[s] | loss 2.35\n",
      "| epoch 1 |  iter 4981 / 9295 | time 157[s] | loss 2.33\n",
      "| epoch 1 |  iter 5001 / 9295 | time 158[s] | loss 2.36\n",
      "| epoch 1 |  iter 5021 / 9295 | time 159[s] | loss 2.35\n",
      "| epoch 1 |  iter 5041 / 9295 | time 159[s] | loss 2.35\n",
      "| epoch 1 |  iter 5061 / 9295 | time 160[s] | loss 2.35\n",
      "| epoch 1 |  iter 5081 / 9295 | time 160[s] | loss 2.37\n",
      "| epoch 1 |  iter 5101 / 9295 | time 161[s] | loss 2.34\n",
      "| epoch 1 |  iter 5121 / 9295 | time 162[s] | loss 2.33\n",
      "| epoch 1 |  iter 5141 / 9295 | time 162[s] | loss 2.32\n",
      "| epoch 1 |  iter 5161 / 9295 | time 163[s] | loss 2.36\n",
      "| epoch 1 |  iter 5181 / 9295 | time 164[s] | loss 2.36\n",
      "| epoch 1 |  iter 5201 / 9295 | time 164[s] | loss 2.35\n",
      "| epoch 1 |  iter 5221 / 9295 | time 165[s] | loss 2.33\n",
      "| epoch 1 |  iter 5241 / 9295 | time 166[s] | loss 2.35\n",
      "| epoch 1 |  iter 5261 / 9295 | time 166[s] | loss 2.38\n",
      "| epoch 1 |  iter 5281 / 9295 | time 167[s] | loss 2.34\n",
      "| epoch 1 |  iter 5301 / 9295 | time 168[s] | loss 2.32\n",
      "| epoch 1 |  iter 5321 / 9295 | time 168[s] | loss 2.35\n",
      "| epoch 1 |  iter 5341 / 9295 | time 169[s] | loss 2.35\n",
      "| epoch 1 |  iter 5361 / 9295 | time 169[s] | loss 2.34\n",
      "| epoch 1 |  iter 5381 / 9295 | time 170[s] | loss 2.33\n",
      "| epoch 1 |  iter 5401 / 9295 | time 171[s] | loss 2.34\n",
      "| epoch 1 |  iter 5421 / 9295 | time 171[s] | loss 2.35\n",
      "| epoch 1 |  iter 5441 / 9295 | time 172[s] | loss 2.33\n",
      "| epoch 1 |  iter 5461 / 9295 | time 173[s] | loss 2.35\n",
      "| epoch 1 |  iter 5481 / 9295 | time 173[s] | loss 2.34\n",
      "| epoch 1 |  iter 5501 / 9295 | time 174[s] | loss 2.36\n",
      "| epoch 1 |  iter 5521 / 9295 | time 175[s] | loss 2.29\n",
      "| epoch 1 |  iter 5541 / 9295 | time 175[s] | loss 2.39\n",
      "| epoch 1 |  iter 5561 / 9295 | time 176[s] | loss 2.33\n",
      "| epoch 1 |  iter 5581 / 9295 | time 177[s] | loss 2.35\n",
      "| epoch 1 |  iter 5601 / 9295 | time 177[s] | loss 2.34\n",
      "| epoch 1 |  iter 5621 / 9295 | time 178[s] | loss 2.31\n",
      "| epoch 1 |  iter 5641 / 9295 | time 178[s] | loss 2.34\n",
      "| epoch 1 |  iter 5661 / 9295 | time 179[s] | loss 2.32\n",
      "| epoch 1 |  iter 5681 / 9295 | time 180[s] | loss 2.35\n",
      "| epoch 1 |  iter 5701 / 9295 | time 180[s] | loss 2.32\n",
      "| epoch 1 |  iter 5721 / 9295 | time 181[s] | loss 2.32\n",
      "| epoch 1 |  iter 5741 / 9295 | time 182[s] | loss 2.33\n",
      "| epoch 1 |  iter 5761 / 9295 | time 182[s] | loss 2.37\n",
      "| epoch 1 |  iter 5781 / 9295 | time 183[s] | loss 2.31\n",
      "| epoch 1 |  iter 5801 / 9295 | time 184[s] | loss 2.32\n",
      "| epoch 1 |  iter 5821 / 9295 | time 184[s] | loss 2.30\n",
      "| epoch 1 |  iter 5841 / 9295 | time 185[s] | loss 2.33\n",
      "| epoch 1 |  iter 5861 / 9295 | time 186[s] | loss 2.30\n",
      "| epoch 1 |  iter 5881 / 9295 | time 186[s] | loss 2.31\n",
      "| epoch 1 |  iter 5901 / 9295 | time 187[s] | loss 2.32\n",
      "| epoch 1 |  iter 5921 / 9295 | time 187[s] | loss 2.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 5941 / 9295 | time 188[s] | loss 2.30\n",
      "| epoch 1 |  iter 5961 / 9295 | time 189[s] | loss 2.31\n",
      "| epoch 1 |  iter 5981 / 9295 | time 189[s] | loss 2.36\n",
      "| epoch 1 |  iter 6001 / 9295 | time 190[s] | loss 2.35\n",
      "| epoch 1 |  iter 6021 / 9295 | time 191[s] | loss 2.33\n",
      "| epoch 1 |  iter 6041 / 9295 | time 191[s] | loss 2.32\n",
      "| epoch 1 |  iter 6061 / 9295 | time 192[s] | loss 2.29\n",
      "| epoch 1 |  iter 6081 / 9295 | time 193[s] | loss 2.33\n",
      "| epoch 1 |  iter 6101 / 9295 | time 193[s] | loss 2.34\n",
      "| epoch 1 |  iter 6121 / 9295 | time 194[s] | loss 2.34\n",
      "| epoch 1 |  iter 6141 / 9295 | time 194[s] | loss 2.30\n",
      "| epoch 1 |  iter 6161 / 9295 | time 195[s] | loss 2.30\n",
      "| epoch 1 |  iter 6181 / 9295 | time 196[s] | loss 2.31\n",
      "| epoch 1 |  iter 6201 / 9295 | time 196[s] | loss 2.29\n",
      "| epoch 1 |  iter 6221 / 9295 | time 197[s] | loss 2.32\n",
      "| epoch 1 |  iter 6241 / 9295 | time 198[s] | loss 2.31\n",
      "| epoch 1 |  iter 6261 / 9295 | time 198[s] | loss 2.36\n",
      "| epoch 1 |  iter 6281 / 9295 | time 199[s] | loss 2.29\n",
      "| epoch 1 |  iter 6301 / 9295 | time 200[s] | loss 2.34\n",
      "| epoch 1 |  iter 6321 / 9295 | time 200[s] | loss 2.30\n",
      "| epoch 1 |  iter 6341 / 9295 | time 201[s] | loss 2.32\n",
      "| epoch 1 |  iter 6361 / 9295 | time 202[s] | loss 2.30\n",
      "| epoch 1 |  iter 6381 / 9295 | time 202[s] | loss 2.30\n",
      "| epoch 1 |  iter 6401 / 9295 | time 203[s] | loss 2.31\n",
      "| epoch 1 |  iter 6421 / 9295 | time 203[s] | loss 2.28\n",
      "| epoch 1 |  iter 6441 / 9295 | time 204[s] | loss 2.26\n",
      "| epoch 1 |  iter 6461 / 9295 | time 205[s] | loss 2.31\n",
      "| epoch 1 |  iter 6481 / 9295 | time 205[s] | loss 2.35\n",
      "| epoch 1 |  iter 6501 / 9295 | time 206[s] | loss 2.32\n",
      "| epoch 1 |  iter 6521 / 9295 | time 207[s] | loss 2.30\n",
      "| epoch 1 |  iter 6541 / 9295 | time 208[s] | loss 2.31\n",
      "| epoch 1 |  iter 6561 / 9295 | time 208[s] | loss 2.27\n",
      "| epoch 1 |  iter 6581 / 9295 | time 209[s] | loss 2.30\n",
      "| epoch 1 |  iter 6601 / 9295 | time 210[s] | loss 2.30\n",
      "| epoch 1 |  iter 6621 / 9295 | time 210[s] | loss 2.30\n",
      "| epoch 1 |  iter 6641 / 9295 | time 211[s] | loss 2.29\n",
      "| epoch 1 |  iter 6661 / 9295 | time 212[s] | loss 2.34\n",
      "| epoch 1 |  iter 6681 / 9295 | time 212[s] | loss 2.32\n",
      "| epoch 1 |  iter 6701 / 9295 | time 213[s] | loss 2.27\n",
      "| epoch 1 |  iter 6721 / 9295 | time 213[s] | loss 2.30\n",
      "| epoch 1 |  iter 6741 / 9295 | time 214[s] | loss 2.29\n",
      "| epoch 1 |  iter 6761 / 9295 | time 215[s] | loss 2.33\n",
      "| epoch 1 |  iter 6781 / 9295 | time 215[s] | loss 2.30\n",
      "| epoch 1 |  iter 6801 / 9295 | time 216[s] | loss 2.29\n",
      "| epoch 1 |  iter 6821 / 9295 | time 217[s] | loss 2.28\n",
      "| epoch 1 |  iter 6841 / 9295 | time 217[s] | loss 2.32\n",
      "| epoch 1 |  iter 6861 / 9295 | time 218[s] | loss 2.32\n",
      "| epoch 1 |  iter 6881 / 9295 | time 219[s] | loss 2.27\n",
      "| epoch 1 |  iter 6901 / 9295 | time 219[s] | loss 2.28\n",
      "| epoch 1 |  iter 6921 / 9295 | time 220[s] | loss 2.30\n",
      "| epoch 1 |  iter 6941 / 9295 | time 220[s] | loss 2.29\n",
      "| epoch 1 |  iter 6961 / 9295 | time 221[s] | loss 2.28\n",
      "| epoch 1 |  iter 6981 / 9295 | time 222[s] | loss 2.28\n",
      "| epoch 1 |  iter 7001 / 9295 | time 222[s] | loss 2.29\n",
      "| epoch 1 |  iter 7021 / 9295 | time 223[s] | loss 2.31\n",
      "| epoch 1 |  iter 7041 / 9295 | time 224[s] | loss 2.29\n",
      "| epoch 1 |  iter 7061 / 9295 | time 224[s] | loss 2.31\n",
      "| epoch 1 |  iter 7081 / 9295 | time 225[s] | loss 2.28\n",
      "| epoch 1 |  iter 7101 / 9295 | time 226[s] | loss 2.29\n",
      "| epoch 1 |  iter 7121 / 9295 | time 226[s] | loss 2.29\n",
      "| epoch 1 |  iter 7141 / 9295 | time 227[s] | loss 2.28\n",
      "| epoch 1 |  iter 7161 / 9295 | time 227[s] | loss 2.29\n",
      "| epoch 1 |  iter 7181 / 9295 | time 228[s] | loss 2.31\n",
      "| epoch 1 |  iter 7201 / 9295 | time 229[s] | loss 2.28\n",
      "| epoch 1 |  iter 7221 / 9295 | time 229[s] | loss 2.28\n",
      "| epoch 1 |  iter 7241 / 9295 | time 230[s] | loss 2.27\n",
      "| epoch 1 |  iter 7261 / 9295 | time 231[s] | loss 2.29\n",
      "| epoch 1 |  iter 7281 / 9295 | time 231[s] | loss 2.27\n",
      "| epoch 1 |  iter 7301 / 9295 | time 232[s] | loss 2.26\n",
      "| epoch 1 |  iter 7321 / 9295 | time 233[s] | loss 2.27\n",
      "| epoch 1 |  iter 7341 / 9295 | time 233[s] | loss 2.27\n",
      "| epoch 1 |  iter 7361 / 9295 | time 234[s] | loss 2.25\n",
      "| epoch 1 |  iter 7381 / 9295 | time 235[s] | loss 2.28\n",
      "| epoch 1 |  iter 7401 / 9295 | time 235[s] | loss 2.25\n",
      "| epoch 1 |  iter 7421 / 9295 | time 236[s] | loss 2.25\n",
      "| epoch 1 |  iter 7441 / 9295 | time 236[s] | loss 2.30\n",
      "| epoch 1 |  iter 7461 / 9295 | time 237[s] | loss 2.30\n",
      "| epoch 1 |  iter 7481 / 9295 | time 238[s] | loss 2.26\n",
      "| epoch 1 |  iter 7501 / 9295 | time 238[s] | loss 2.24\n",
      "| epoch 1 |  iter 7521 / 9295 | time 239[s] | loss 2.26\n",
      "| epoch 1 |  iter 7541 / 9295 | time 240[s] | loss 2.28\n",
      "| epoch 1 |  iter 7561 / 9295 | time 240[s] | loss 2.23\n",
      "| epoch 1 |  iter 7581 / 9295 | time 241[s] | loss 2.27\n",
      "| epoch 1 |  iter 7601 / 9295 | time 242[s] | loss 2.26\n",
      "| epoch 1 |  iter 7621 / 9295 | time 242[s] | loss 2.26\n",
      "| epoch 1 |  iter 7641 / 9295 | time 243[s] | loss 2.26\n",
      "| epoch 1 |  iter 7661 / 9295 | time 243[s] | loss 2.25\n",
      "| epoch 1 |  iter 7681 / 9295 | time 244[s] | loss 2.24\n",
      "| epoch 1 |  iter 7701 / 9295 | time 245[s] | loss 2.26\n",
      "| epoch 1 |  iter 7721 / 9295 | time 245[s] | loss 2.27\n",
      "| epoch 1 |  iter 7741 / 9295 | time 246[s] | loss 2.24\n",
      "| epoch 1 |  iter 7761 / 9295 | time 247[s] | loss 2.24\n",
      "| epoch 1 |  iter 7781 / 9295 | time 247[s] | loss 2.26\n",
      "| epoch 1 |  iter 7801 / 9295 | time 248[s] | loss 2.24\n",
      "| epoch 1 |  iter 7821 / 9295 | time 249[s] | loss 2.29\n",
      "| epoch 1 |  iter 7841 / 9295 | time 249[s] | loss 2.27\n",
      "| epoch 1 |  iter 7861 / 9295 | time 250[s] | loss 2.23\n",
      "| epoch 1 |  iter 7881 / 9295 | time 251[s] | loss 2.29\n",
      "| epoch 1 |  iter 7901 / 9295 | time 251[s] | loss 2.27\n",
      "| epoch 1 |  iter 7921 / 9295 | time 252[s] | loss 2.27\n",
      "| epoch 1 |  iter 7941 / 9295 | time 253[s] | loss 2.23\n",
      "| epoch 1 |  iter 7961 / 9295 | time 253[s] | loss 2.24\n",
      "| epoch 1 |  iter 7981 / 9295 | time 254[s] | loss 2.29\n",
      "| epoch 1 |  iter 8001 / 9295 | time 254[s] | loss 2.26\n",
      "| epoch 1 |  iter 8021 / 9295 | time 255[s] | loss 2.26\n",
      "| epoch 1 |  iter 8041 / 9295 | time 256[s] | loss 2.26\n",
      "| epoch 1 |  iter 8061 / 9295 | time 256[s] | loss 2.25\n",
      "| epoch 1 |  iter 8081 / 9295 | time 257[s] | loss 2.27\n",
      "| epoch 1 |  iter 8101 / 9295 | time 258[s] | loss 2.27\n",
      "| epoch 1 |  iter 8121 / 9295 | time 258[s] | loss 2.25\n",
      "| epoch 1 |  iter 8141 / 9295 | time 259[s] | loss 2.26\n",
      "| epoch 1 |  iter 8161 / 9295 | time 260[s] | loss 2.26\n",
      "| epoch 1 |  iter 8181 / 9295 | time 260[s] | loss 2.24\n",
      "| epoch 1 |  iter 8201 / 9295 | time 261[s] | loss 2.27\n",
      "| epoch 1 |  iter 8221 / 9295 | time 262[s] | loss 2.25\n",
      "| epoch 1 |  iter 8241 / 9295 | time 262[s] | loss 2.23\n",
      "| epoch 1 |  iter 8261 / 9295 | time 263[s] | loss 2.21\n",
      "| epoch 1 |  iter 8281 / 9295 | time 263[s] | loss 2.26\n",
      "| epoch 1 |  iter 8301 / 9295 | time 264[s] | loss 2.24\n",
      "| epoch 1 |  iter 8321 / 9295 | time 265[s] | loss 2.22\n",
      "| epoch 1 |  iter 8341 / 9295 | time 265[s] | loss 2.25\n",
      "| epoch 1 |  iter 8361 / 9295 | time 266[s] | loss 2.24\n",
      "| epoch 1 |  iter 8381 / 9295 | time 267[s] | loss 2.27\n",
      "| epoch 1 |  iter 8401 / 9295 | time 267[s] | loss 2.29\n",
      "| epoch 1 |  iter 8421 / 9295 | time 268[s] | loss 2.23\n",
      "| epoch 1 |  iter 8441 / 9295 | time 269[s] | loss 2.26\n",
      "| epoch 1 |  iter 8461 / 9295 | time 269[s] | loss 2.24\n",
      "| epoch 1 |  iter 8481 / 9295 | time 270[s] | loss 2.24\n",
      "| epoch 1 |  iter 8501 / 9295 | time 270[s] | loss 2.21\n",
      "| epoch 1 |  iter 8521 / 9295 | time 271[s] | loss 2.18\n",
      "| epoch 1 |  iter 8541 / 9295 | time 272[s] | loss 2.24\n",
      "| epoch 1 |  iter 8561 / 9295 | time 272[s] | loss 2.25\n",
      "| epoch 1 |  iter 8581 / 9295 | time 273[s] | loss 2.24\n",
      "| epoch 1 |  iter 8601 / 9295 | time 274[s] | loss 2.25\n",
      "| epoch 1 |  iter 8621 / 9295 | time 274[s] | loss 2.25\n",
      "| epoch 1 |  iter 8641 / 9295 | time 275[s] | loss 2.22\n",
      "| epoch 1 |  iter 8661 / 9295 | time 276[s] | loss 2.24\n",
      "| epoch 1 |  iter 8681 / 9295 | time 276[s] | loss 2.23\n",
      "| epoch 1 |  iter 8701 / 9295 | time 277[s] | loss 2.24\n",
      "| epoch 1 |  iter 8721 / 9295 | time 278[s] | loss 2.22\n",
      "| epoch 1 |  iter 8741 / 9295 | time 278[s] | loss 2.23\n",
      "| epoch 1 |  iter 8761 / 9295 | time 279[s] | loss 2.23\n",
      "| epoch 1 |  iter 8781 / 9295 | time 279[s] | loss 2.23\n",
      "| epoch 1 |  iter 8801 / 9295 | time 280[s] | loss 2.22\n",
      "| epoch 1 |  iter 8821 / 9295 | time 281[s] | loss 2.25\n",
      "| epoch 1 |  iter 8841 / 9295 | time 281[s] | loss 2.25\n",
      "| epoch 1 |  iter 8861 / 9295 | time 282[s] | loss 2.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 8881 / 9295 | time 283[s] | loss 2.24\n",
      "| epoch 1 |  iter 8901 / 9295 | time 283[s] | loss 2.21\n",
      "| epoch 1 |  iter 8921 / 9295 | time 284[s] | loss 2.24\n",
      "| epoch 1 |  iter 8941 / 9295 | time 285[s] | loss 2.24\n",
      "| epoch 1 |  iter 8961 / 9295 | time 285[s] | loss 2.20\n",
      "| epoch 1 |  iter 8981 / 9295 | time 286[s] | loss 2.22\n",
      "| epoch 1 |  iter 9001 / 9295 | time 287[s] | loss 2.21\n",
      "| epoch 1 |  iter 9021 / 9295 | time 287[s] | loss 2.21\n",
      "| epoch 1 |  iter 9041 / 9295 | time 288[s] | loss 2.24\n",
      "| epoch 1 |  iter 9061 / 9295 | time 288[s] | loss 2.25\n",
      "| epoch 1 |  iter 9081 / 9295 | time 289[s] | loss 2.27\n",
      "| epoch 1 |  iter 9101 / 9295 | time 290[s] | loss 2.21\n",
      "| epoch 1 |  iter 9121 / 9295 | time 290[s] | loss 2.26\n",
      "| epoch 1 |  iter 9141 / 9295 | time 291[s] | loss 2.22\n",
      "| epoch 1 |  iter 9161 / 9295 | time 292[s] | loss 2.23\n",
      "| epoch 1 |  iter 9181 / 9295 | time 292[s] | loss 2.20\n",
      "| epoch 1 |  iter 9201 / 9295 | time 293[s] | loss 2.23\n",
      "| epoch 1 |  iter 9221 / 9295 | time 294[s] | loss 2.23\n",
      "| epoch 1 |  iter 9241 / 9295 | time 294[s] | loss 2.20\n",
      "| epoch 1 |  iter 9261 / 9295 | time 295[s] | loss 2.22\n",
      "| epoch 1 |  iter 9281 / 9295 | time 296[s] | loss 2.21\n",
      "| epoch 2 |  iter 1 / 9295 | time 296[s] | loss 2.21\n",
      "| epoch 2 |  iter 21 / 9295 | time 297[s] | loss 2.18\n",
      "| epoch 2 |  iter 41 / 9295 | time 297[s] | loss 2.14\n",
      "| epoch 2 |  iter 61 / 9295 | time 298[s] | loss 2.18\n",
      "| epoch 2 |  iter 81 / 9295 | time 299[s] | loss 2.19\n",
      "| epoch 2 |  iter 101 / 9295 | time 299[s] | loss 2.18\n",
      "| epoch 2 |  iter 121 / 9295 | time 300[s] | loss 2.18\n",
      "| epoch 2 |  iter 141 / 9295 | time 301[s] | loss 2.16\n",
      "| epoch 2 |  iter 161 / 9295 | time 301[s] | loss 2.18\n",
      "| epoch 2 |  iter 181 / 9295 | time 302[s] | loss 2.17\n",
      "| epoch 2 |  iter 201 / 9295 | time 303[s] | loss 2.19\n",
      "| epoch 2 |  iter 221 / 9295 | time 303[s] | loss 2.20\n",
      "| epoch 2 |  iter 241 / 9295 | time 304[s] | loss 2.15\n",
      "| epoch 2 |  iter 261 / 9295 | time 304[s] | loss 2.18\n",
      "| epoch 2 |  iter 281 / 9295 | time 305[s] | loss 2.19\n",
      "| epoch 2 |  iter 301 / 9295 | time 306[s] | loss 2.18\n",
      "| epoch 2 |  iter 321 / 9295 | time 306[s] | loss 2.19\n",
      "| epoch 2 |  iter 341 / 9295 | time 307[s] | loss 2.18\n",
      "| epoch 2 |  iter 361 / 9295 | time 308[s] | loss 2.18\n",
      "| epoch 2 |  iter 381 / 9295 | time 308[s] | loss 2.17\n",
      "| epoch 2 |  iter 401 / 9295 | time 309[s] | loss 2.17\n",
      "| epoch 2 |  iter 421 / 9295 | time 310[s] | loss 2.16\n",
      "| epoch 2 |  iter 441 / 9295 | time 310[s] | loss 2.15\n",
      "| epoch 2 |  iter 461 / 9295 | time 311[s] | loss 2.17\n",
      "| epoch 2 |  iter 481 / 9295 | time 311[s] | loss 2.19\n",
      "| epoch 2 |  iter 501 / 9295 | time 312[s] | loss 2.19\n",
      "| epoch 2 |  iter 521 / 9295 | time 313[s] | loss 2.13\n",
      "| epoch 2 |  iter 541 / 9295 | time 313[s] | loss 2.19\n",
      "| epoch 2 |  iter 561 / 9295 | time 314[s] | loss 2.19\n",
      "| epoch 2 |  iter 581 / 9295 | time 315[s] | loss 2.16\n",
      "| epoch 2 |  iter 601 / 9295 | time 315[s] | loss 2.16\n",
      "| epoch 2 |  iter 621 / 9295 | time 316[s] | loss 2.17\n",
      "| epoch 2 |  iter 641 / 9295 | time 317[s] | loss 2.16\n",
      "| epoch 2 |  iter 661 / 9295 | time 317[s] | loss 2.17\n",
      "| epoch 2 |  iter 681 / 9295 | time 318[s] | loss 2.17\n",
      "| epoch 2 |  iter 701 / 9295 | time 319[s] | loss 2.17\n",
      "| epoch 2 |  iter 721 / 9295 | time 319[s] | loss 2.17\n",
      "| epoch 2 |  iter 741 / 9295 | time 320[s] | loss 2.17\n",
      "| epoch 2 |  iter 761 / 9295 | time 320[s] | loss 2.16\n",
      "| epoch 2 |  iter 781 / 9295 | time 321[s] | loss 2.18\n",
      "| epoch 2 |  iter 801 / 9295 | time 322[s] | loss 2.14\n",
      "| epoch 2 |  iter 821 / 9295 | time 322[s] | loss 2.19\n",
      "| epoch 2 |  iter 841 / 9295 | time 323[s] | loss 2.16\n",
      "| epoch 2 |  iter 861 / 9295 | time 324[s] | loss 2.16\n",
      "| epoch 2 |  iter 881 / 9295 | time 324[s] | loss 2.16\n",
      "| epoch 2 |  iter 901 / 9295 | time 325[s] | loss 2.16\n",
      "| epoch 2 |  iter 921 / 9295 | time 325[s] | loss 2.20\n",
      "| epoch 2 |  iter 941 / 9295 | time 326[s] | loss 2.16\n",
      "| epoch 2 |  iter 961 / 9295 | time 327[s] | loss 2.19\n",
      "| epoch 2 |  iter 981 / 9295 | time 327[s] | loss 2.17\n",
      "| epoch 2 |  iter 1001 / 9295 | time 328[s] | loss 2.16\n",
      "| epoch 2 |  iter 1021 / 9295 | time 329[s] | loss 2.15\n",
      "| epoch 2 |  iter 1041 / 9295 | time 329[s] | loss 2.20\n",
      "| epoch 2 |  iter 1061 / 9295 | time 330[s] | loss 2.15\n",
      "| epoch 2 |  iter 1081 / 9295 | time 331[s] | loss 2.17\n",
      "| epoch 2 |  iter 1101 / 9295 | time 331[s] | loss 2.16\n",
      "| epoch 2 |  iter 1121 / 9295 | time 332[s] | loss 2.15\n",
      "| epoch 2 |  iter 1141 / 9295 | time 332[s] | loss 2.16\n",
      "| epoch 2 |  iter 1161 / 9295 | time 333[s] | loss 2.13\n",
      "| epoch 2 |  iter 1181 / 9295 | time 334[s] | loss 2.16\n",
      "| epoch 2 |  iter 1201 / 9295 | time 334[s] | loss 2.13\n",
      "| epoch 2 |  iter 1221 / 9295 | time 335[s] | loss 2.11\n",
      "| epoch 2 |  iter 1241 / 9295 | time 336[s] | loss 2.16\n",
      "| epoch 2 |  iter 1261 / 9295 | time 336[s] | loss 2.18\n",
      "| epoch 2 |  iter 1281 / 9295 | time 337[s] | loss 2.15\n",
      "| epoch 2 |  iter 1301 / 9295 | time 338[s] | loss 2.15\n",
      "| epoch 2 |  iter 1321 / 9295 | time 338[s] | loss 2.16\n",
      "| epoch 2 |  iter 1341 / 9295 | time 339[s] | loss 2.18\n",
      "| epoch 2 |  iter 1361 / 9295 | time 340[s] | loss 2.15\n",
      "| epoch 2 |  iter 1381 / 9295 | time 340[s] | loss 2.14\n",
      "| epoch 2 |  iter 1401 / 9295 | time 341[s] | loss 2.13\n",
      "| epoch 2 |  iter 1421 / 9295 | time 341[s] | loss 2.14\n",
      "| epoch 2 |  iter 1441 / 9295 | time 342[s] | loss 2.14\n",
      "| epoch 2 |  iter 1461 / 9295 | time 343[s] | loss 2.13\n",
      "| epoch 2 |  iter 1481 / 9295 | time 343[s] | loss 2.16\n",
      "| epoch 2 |  iter 1501 / 9295 | time 344[s] | loss 2.14\n",
      "| epoch 2 |  iter 1521 / 9295 | time 345[s] | loss 2.16\n",
      "| epoch 2 |  iter 1541 / 9295 | time 345[s] | loss 2.14\n",
      "| epoch 2 |  iter 1561 / 9295 | time 346[s] | loss 2.12\n",
      "| epoch 2 |  iter 1581 / 9295 | time 347[s] | loss 2.17\n",
      "| epoch 2 |  iter 1601 / 9295 | time 347[s] | loss 2.17\n",
      "| epoch 2 |  iter 1621 / 9295 | time 348[s] | loss 2.17\n",
      "| epoch 2 |  iter 1641 / 9295 | time 348[s] | loss 2.17\n",
      "| epoch 2 |  iter 1661 / 9295 | time 349[s] | loss 2.12\n",
      "| epoch 2 |  iter 1681 / 9295 | time 350[s] | loss 2.14\n",
      "| epoch 2 |  iter 1701 / 9295 | time 350[s] | loss 2.17\n",
      "| epoch 2 |  iter 1721 / 9295 | time 351[s] | loss 2.12\n",
      "| epoch 2 |  iter 1741 / 9295 | time 352[s] | loss 2.17\n",
      "| epoch 2 |  iter 1761 / 9295 | time 352[s] | loss 2.18\n",
      "| epoch 2 |  iter 1781 / 9295 | time 353[s] | loss 2.12\n",
      "| epoch 2 |  iter 1801 / 9295 | time 354[s] | loss 2.13\n",
      "| epoch 2 |  iter 1821 / 9295 | time 354[s] | loss 2.12\n",
      "| epoch 2 |  iter 1841 / 9295 | time 355[s] | loss 2.12\n",
      "| epoch 2 |  iter 1861 / 9295 | time 356[s] | loss 2.16\n",
      "| epoch 2 |  iter 1881 / 9295 | time 356[s] | loss 2.16\n",
      "| epoch 2 |  iter 1901 / 9295 | time 357[s] | loss 2.15\n",
      "| epoch 2 |  iter 1921 / 9295 | time 357[s] | loss 2.12\n",
      "| epoch 2 |  iter 1941 / 9295 | time 358[s] | loss 2.17\n",
      "| epoch 2 |  iter 1961 / 9295 | time 359[s] | loss 2.10\n",
      "| epoch 2 |  iter 1981 / 9295 | time 359[s] | loss 2.13\n",
      "| epoch 2 |  iter 2001 / 9295 | time 360[s] | loss 2.14\n",
      "| epoch 2 |  iter 2021 / 9295 | time 361[s] | loss 2.12\n",
      "| epoch 2 |  iter 2041 / 9295 | time 361[s] | loss 2.09\n",
      "| epoch 2 |  iter 2061 / 9295 | time 362[s] | loss 2.14\n",
      "| epoch 2 |  iter 2081 / 9295 | time 362[s] | loss 2.14\n",
      "| epoch 2 |  iter 2101 / 9295 | time 363[s] | loss 2.12\n",
      "| epoch 2 |  iter 2121 / 9295 | time 364[s] | loss 2.14\n",
      "| epoch 2 |  iter 2141 / 9295 | time 364[s] | loss 2.14\n",
      "| epoch 2 |  iter 2161 / 9295 | time 365[s] | loss 2.16\n",
      "| epoch 2 |  iter 2181 / 9295 | time 366[s] | loss 2.15\n",
      "| epoch 2 |  iter 2201 / 9295 | time 366[s] | loss 2.14\n",
      "| epoch 2 |  iter 2221 / 9295 | time 367[s] | loss 2.14\n",
      "| epoch 2 |  iter 2241 / 9295 | time 368[s] | loss 2.11\n",
      "| epoch 2 |  iter 2261 / 9295 | time 368[s] | loss 2.11\n",
      "| epoch 2 |  iter 2281 / 9295 | time 369[s] | loss 2.11\n",
      "| epoch 2 |  iter 2301 / 9295 | time 370[s] | loss 2.09\n",
      "| epoch 2 |  iter 2321 / 9295 | time 370[s] | loss 2.15\n",
      "| epoch 2 |  iter 2341 / 9295 | time 371[s] | loss 2.14\n",
      "| epoch 2 |  iter 2361 / 9295 | time 371[s] | loss 2.09\n",
      "| epoch 2 |  iter 2381 / 9295 | time 372[s] | loss 2.08\n",
      "| epoch 2 |  iter 2401 / 9295 | time 373[s] | loss 2.16\n",
      "| epoch 2 |  iter 2421 / 9295 | time 373[s] | loss 2.16\n",
      "| epoch 2 |  iter 2441 / 9295 | time 374[s] | loss 2.14\n",
      "| epoch 2 |  iter 2461 / 9295 | time 375[s] | loss 2.11\n",
      "| epoch 2 |  iter 2481 / 9295 | time 375[s] | loss 2.11\n",
      "| epoch 2 |  iter 2501 / 9295 | time 376[s] | loss 2.13\n",
      "| epoch 2 |  iter 2521 / 9295 | time 377[s] | loss 2.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 2541 / 9295 | time 377[s] | loss 2.11\n",
      "| epoch 2 |  iter 2561 / 9295 | time 378[s] | loss 2.14\n",
      "| epoch 2 |  iter 2581 / 9295 | time 378[s] | loss 2.17\n",
      "| epoch 2 |  iter 2601 / 9295 | time 379[s] | loss 2.15\n",
      "| epoch 2 |  iter 2621 / 9295 | time 380[s] | loss 2.15\n",
      "| epoch 2 |  iter 2641 / 9295 | time 380[s] | loss 2.10\n",
      "| epoch 2 |  iter 2661 / 9295 | time 381[s] | loss 2.14\n",
      "| epoch 2 |  iter 2681 / 9295 | time 382[s] | loss 2.13\n",
      "| epoch 2 |  iter 2701 / 9295 | time 382[s] | loss 2.13\n",
      "| epoch 2 |  iter 2721 / 9295 | time 383[s] | loss 2.13\n",
      "| epoch 2 |  iter 2741 / 9295 | time 384[s] | loss 2.07\n",
      "| epoch 2 |  iter 2761 / 9295 | time 384[s] | loss 2.16\n",
      "| epoch 2 |  iter 2781 / 9295 | time 385[s] | loss 2.12\n",
      "| epoch 2 |  iter 2801 / 9295 | time 386[s] | loss 2.13\n",
      "| epoch 2 |  iter 2821 / 9295 | time 386[s] | loss 2.13\n",
      "| epoch 2 |  iter 2841 / 9295 | time 387[s] | loss 2.13\n",
      "| epoch 2 |  iter 2861 / 9295 | time 387[s] | loss 2.11\n",
      "| epoch 2 |  iter 2881 / 9295 | time 388[s] | loss 2.11\n",
      "| epoch 2 |  iter 2901 / 9295 | time 389[s] | loss 2.12\n",
      "| epoch 2 |  iter 2921 / 9295 | time 389[s] | loss 2.13\n",
      "| epoch 2 |  iter 2941 / 9295 | time 390[s] | loss 2.13\n",
      "| epoch 2 |  iter 2961 / 9295 | time 391[s] | loss 2.11\n",
      "| epoch 2 |  iter 2981 / 9295 | time 391[s] | loss 2.17\n",
      "| epoch 2 |  iter 3001 / 9295 | time 392[s] | loss 2.12\n",
      "| epoch 2 |  iter 3021 / 9295 | time 393[s] | loss 2.09\n",
      "| epoch 2 |  iter 3041 / 9295 | time 393[s] | loss 2.07\n",
      "| epoch 2 |  iter 3061 / 9295 | time 394[s] | loss 2.12\n",
      "| epoch 2 |  iter 3081 / 9295 | time 394[s] | loss 2.14\n",
      "| epoch 2 |  iter 3101 / 9295 | time 395[s] | loss 2.13\n",
      "| epoch 2 |  iter 3121 / 9295 | time 396[s] | loss 2.07\n",
      "| epoch 2 |  iter 3141 / 9295 | time 396[s] | loss 2.09\n",
      "| epoch 2 |  iter 3161 / 9295 | time 397[s] | loss 2.16\n",
      "| epoch 2 |  iter 3181 / 9295 | time 398[s] | loss 2.15\n",
      "| epoch 2 |  iter 3201 / 9295 | time 398[s] | loss 2.12\n",
      "| epoch 2 |  iter 3221 / 9295 | time 399[s] | loss 2.10\n",
      "| epoch 2 |  iter 3241 / 9295 | time 400[s] | loss 2.11\n",
      "| epoch 2 |  iter 3261 / 9295 | time 400[s] | loss 2.11\n",
      "| epoch 2 |  iter 3281 / 9295 | time 401[s] | loss 2.11\n",
      "| epoch 2 |  iter 3301 / 9295 | time 401[s] | loss 2.10\n",
      "| epoch 2 |  iter 3321 / 9295 | time 402[s] | loss 2.11\n",
      "| epoch 2 |  iter 3341 / 9295 | time 403[s] | loss 2.15\n",
      "| epoch 2 |  iter 3361 / 9295 | time 403[s] | loss 2.09\n",
      "| epoch 2 |  iter 3381 / 9295 | time 404[s] | loss 2.10\n",
      "| epoch 2 |  iter 3401 / 9295 | time 405[s] | loss 2.12\n",
      "| epoch 2 |  iter 3421 / 9295 | time 405[s] | loss 2.05\n",
      "| epoch 2 |  iter 3441 / 9295 | time 406[s] | loss 2.09\n",
      "| epoch 2 |  iter 3461 / 9295 | time 407[s] | loss 2.12\n",
      "| epoch 2 |  iter 3481 / 9295 | time 407[s] | loss 2.14\n",
      "| epoch 2 |  iter 3501 / 9295 | time 408[s] | loss 2.11\n",
      "| epoch 2 |  iter 3521 / 9295 | time 409[s] | loss 2.12\n",
      "| epoch 2 |  iter 3541 / 9295 | time 409[s] | loss 2.09\n",
      "| epoch 2 |  iter 3561 / 9295 | time 410[s] | loss 2.07\n",
      "| epoch 2 |  iter 3581 / 9295 | time 410[s] | loss 2.11\n",
      "| epoch 2 |  iter 3601 / 9295 | time 411[s] | loss 2.07\n",
      "| epoch 2 |  iter 3621 / 9295 | time 412[s] | loss 2.10\n",
      "| epoch 2 |  iter 3641 / 9295 | time 412[s] | loss 2.10\n",
      "| epoch 2 |  iter 3661 / 9295 | time 413[s] | loss 2.07\n",
      "| epoch 2 |  iter 3681 / 9295 | time 414[s] | loss 2.14\n",
      "| epoch 2 |  iter 3701 / 9295 | time 414[s] | loss 2.05\n",
      "| epoch 2 |  iter 3721 / 9295 | time 415[s] | loss 2.07\n",
      "| epoch 2 |  iter 3741 / 9295 | time 416[s] | loss 2.11\n",
      "| epoch 2 |  iter 3761 / 9295 | time 416[s] | loss 2.12\n",
      "| epoch 2 |  iter 3781 / 9295 | time 417[s] | loss 2.10\n",
      "| epoch 2 |  iter 3801 / 9295 | time 417[s] | loss 2.10\n",
      "| epoch 2 |  iter 3821 / 9295 | time 418[s] | loss 2.10\n",
      "| epoch 2 |  iter 3841 / 9295 | time 419[s] | loss 2.09\n",
      "| epoch 2 |  iter 3861 / 9295 | time 419[s] | loss 2.09\n",
      "| epoch 2 |  iter 3881 / 9295 | time 420[s] | loss 2.11\n",
      "| epoch 2 |  iter 3901 / 9295 | time 421[s] | loss 2.13\n",
      "| epoch 2 |  iter 3921 / 9295 | time 421[s] | loss 2.12\n",
      "| epoch 2 |  iter 3941 / 9295 | time 422[s] | loss 2.15\n",
      "| epoch 2 |  iter 3961 / 9295 | time 423[s] | loss 2.08\n",
      "| epoch 2 |  iter 3981 / 9295 | time 423[s] | loss 2.11\n",
      "| epoch 2 |  iter 4001 / 9295 | time 424[s] | loss 2.08\n",
      "| epoch 2 |  iter 4021 / 9295 | time 424[s] | loss 2.10\n",
      "| epoch 2 |  iter 4041 / 9295 | time 425[s] | loss 2.10\n",
      "| epoch 2 |  iter 4061 / 9295 | time 426[s] | loss 2.09\n",
      "| epoch 2 |  iter 4081 / 9295 | time 426[s] | loss 2.10\n",
      "| epoch 2 |  iter 4101 / 9295 | time 427[s] | loss 2.10\n",
      "| epoch 2 |  iter 4121 / 9295 | time 428[s] | loss 2.11\n",
      "| epoch 2 |  iter 4141 / 9295 | time 428[s] | loss 2.08\n",
      "| epoch 2 |  iter 4161 / 9295 | time 429[s] | loss 2.10\n",
      "| epoch 2 |  iter 4181 / 9295 | time 429[s] | loss 2.11\n",
      "| epoch 2 |  iter 4201 / 9295 | time 430[s] | loss 2.06\n",
      "| epoch 2 |  iter 4221 / 9295 | time 431[s] | loss 2.08\n",
      "| epoch 2 |  iter 4241 / 9295 | time 431[s] | loss 2.12\n",
      "| epoch 2 |  iter 4261 / 9295 | time 432[s] | loss 2.06\n",
      "| epoch 2 |  iter 4281 / 9295 | time 433[s] | loss 2.06\n",
      "| epoch 2 |  iter 4301 / 9295 | time 433[s] | loss 2.10\n",
      "| epoch 2 |  iter 4321 / 9295 | time 434[s] | loss 2.07\n",
      "| epoch 2 |  iter 4341 / 9295 | time 435[s] | loss 2.06\n",
      "| epoch 2 |  iter 4361 / 9295 | time 435[s] | loss 2.07\n",
      "| epoch 2 |  iter 4381 / 9295 | time 436[s] | loss 2.12\n",
      "| epoch 2 |  iter 4401 / 9295 | time 436[s] | loss 2.09\n",
      "| epoch 2 |  iter 4421 / 9295 | time 437[s] | loss 2.08\n",
      "| epoch 2 |  iter 4441 / 9295 | time 438[s] | loss 2.07\n",
      "| epoch 2 |  iter 4461 / 9295 | time 438[s] | loss 2.09\n",
      "| epoch 2 |  iter 4481 / 9295 | time 439[s] | loss 2.07\n",
      "| epoch 2 |  iter 4501 / 9295 | time 440[s] | loss 2.09\n",
      "| epoch 2 |  iter 4521 / 9295 | time 440[s] | loss 2.10\n",
      "| epoch 2 |  iter 4541 / 9295 | time 441[s] | loss 2.08\n",
      "| epoch 2 |  iter 4561 / 9295 | time 442[s] | loss 2.07\n",
      "| epoch 2 |  iter 4581 / 9295 | time 442[s] | loss 2.13\n",
      "| epoch 2 |  iter 4601 / 9295 | time 443[s] | loss 2.09\n",
      "| epoch 2 |  iter 4621 / 9295 | time 443[s] | loss 2.07\n",
      "| epoch 2 |  iter 4641 / 9295 | time 444[s] | loss 2.09\n",
      "| epoch 2 |  iter 4661 / 9295 | time 445[s] | loss 2.10\n",
      "| epoch 2 |  iter 4681 / 9295 | time 445[s] | loss 2.08\n",
      "| epoch 2 |  iter 4701 / 9295 | time 446[s] | loss 2.10\n",
      "| epoch 2 |  iter 4721 / 9295 | time 447[s] | loss 2.10\n",
      "| epoch 2 |  iter 4741 / 9295 | time 447[s] | loss 2.06\n",
      "| epoch 2 |  iter 4761 / 9295 | time 448[s] | loss 2.06\n",
      "| epoch 2 |  iter 4781 / 9295 | time 449[s] | loss 2.09\n",
      "| epoch 2 |  iter 4801 / 9295 | time 449[s] | loss 2.12\n",
      "| epoch 2 |  iter 4821 / 9295 | time 450[s] | loss 2.10\n",
      "| epoch 2 |  iter 4841 / 9295 | time 450[s] | loss 2.07\n",
      "| epoch 2 |  iter 4861 / 9295 | time 451[s] | loss 2.10\n",
      "| epoch 2 |  iter 4881 / 9295 | time 452[s] | loss 2.08\n",
      "| epoch 2 |  iter 4901 / 9295 | time 452[s] | loss 2.07\n",
      "| epoch 2 |  iter 4921 / 9295 | time 453[s] | loss 2.06\n",
      "| epoch 2 |  iter 4941 / 9295 | time 454[s] | loss 2.08\n",
      "| epoch 2 |  iter 4961 / 9295 | time 454[s] | loss 2.07\n",
      "| epoch 2 |  iter 4981 / 9295 | time 455[s] | loss 2.07\n",
      "| epoch 2 |  iter 5001 / 9295 | time 456[s] | loss 2.07\n",
      "| epoch 2 |  iter 5021 / 9295 | time 456[s] | loss 2.09\n",
      "| epoch 2 |  iter 5041 / 9295 | time 457[s] | loss 2.10\n",
      "| epoch 2 |  iter 5061 / 9295 | time 457[s] | loss 2.08\n",
      "| epoch 2 |  iter 5081 / 9295 | time 458[s] | loss 2.05\n",
      "| epoch 2 |  iter 5101 / 9295 | time 459[s] | loss 2.10\n",
      "| epoch 2 |  iter 5121 / 9295 | time 460[s] | loss 2.07\n",
      "| epoch 2 |  iter 5141 / 9295 | time 460[s] | loss 2.06\n",
      "| epoch 2 |  iter 5161 / 9295 | time 461[s] | loss 2.08\n",
      "| epoch 2 |  iter 5181 / 9295 | time 461[s] | loss 2.09\n",
      "| epoch 2 |  iter 5201 / 9295 | time 462[s] | loss 2.08\n",
      "| epoch 2 |  iter 5221 / 9295 | time 463[s] | loss 2.10\n",
      "| epoch 2 |  iter 5241 / 9295 | time 463[s] | loss 2.07\n",
      "| epoch 2 |  iter 5261 / 9295 | time 464[s] | loss 2.07\n",
      "| epoch 2 |  iter 5281 / 9295 | time 465[s] | loss 2.09\n",
      "| epoch 2 |  iter 5301 / 9295 | time 465[s] | loss 2.06\n",
      "| epoch 2 |  iter 5321 / 9295 | time 466[s] | loss 2.08\n",
      "| epoch 2 |  iter 5341 / 9295 | time 467[s] | loss 2.05\n",
      "| epoch 2 |  iter 5361 / 9295 | time 467[s] | loss 2.09\n",
      "| epoch 2 |  iter 5381 / 9295 | time 468[s] | loss 2.06\n",
      "| epoch 2 |  iter 5401 / 9295 | time 469[s] | loss 2.10\n",
      "| epoch 2 |  iter 5421 / 9295 | time 469[s] | loss 2.06\n",
      "| epoch 2 |  iter 5441 / 9295 | time 470[s] | loss 2.04\n",
      "| epoch 2 |  iter 5461 / 9295 | time 470[s] | loss 2.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 5481 / 9295 | time 471[s] | loss 2.09\n",
      "| epoch 2 |  iter 5501 / 9295 | time 472[s] | loss 2.07\n",
      "| epoch 2 |  iter 5521 / 9295 | time 472[s] | loss 2.06\n",
      "| epoch 2 |  iter 5541 / 9295 | time 473[s] | loss 2.06\n",
      "| epoch 2 |  iter 5561 / 9295 | time 474[s] | loss 2.08\n",
      "| epoch 2 |  iter 5581 / 9295 | time 474[s] | loss 2.05\n",
      "| epoch 2 |  iter 5601 / 9295 | time 475[s] | loss 2.08\n",
      "| epoch 2 |  iter 5621 / 9295 | time 475[s] | loss 2.06\n",
      "| epoch 2 |  iter 5641 / 9295 | time 476[s] | loss 2.09\n",
      "| epoch 2 |  iter 5661 / 9295 | time 477[s] | loss 2.08\n",
      "| epoch 2 |  iter 5681 / 9295 | time 477[s] | loss 2.05\n",
      "| epoch 2 |  iter 5701 / 9295 | time 478[s] | loss 2.08\n",
      "| epoch 2 |  iter 5721 / 9295 | time 479[s] | loss 2.07\n",
      "| epoch 2 |  iter 5741 / 9295 | time 479[s] | loss 2.04\n",
      "| epoch 2 |  iter 5761 / 9295 | time 480[s] | loss 2.06\n",
      "| epoch 2 |  iter 5781 / 9295 | time 481[s] | loss 2.08\n",
      "| epoch 2 |  iter 5801 / 9295 | time 481[s] | loss 2.07\n",
      "| epoch 2 |  iter 5821 / 9295 | time 482[s] | loss 2.08\n",
      "| epoch 2 |  iter 5841 / 9295 | time 482[s] | loss 2.07\n",
      "| epoch 2 |  iter 5861 / 9295 | time 483[s] | loss 2.10\n",
      "| epoch 2 |  iter 5881 / 9295 | time 484[s] | loss 2.06\n",
      "| epoch 2 |  iter 5901 / 9295 | time 484[s] | loss 2.05\n",
      "| epoch 2 |  iter 5921 / 9295 | time 485[s] | loss 2.09\n",
      "| epoch 2 |  iter 5941 / 9295 | time 486[s] | loss 2.02\n",
      "| epoch 2 |  iter 5961 / 9295 | time 486[s] | loss 2.04\n",
      "| epoch 2 |  iter 5981 / 9295 | time 487[s] | loss 2.06\n",
      "| epoch 2 |  iter 6001 / 9295 | time 488[s] | loss 2.06\n",
      "| epoch 2 |  iter 6021 / 9295 | time 488[s] | loss 2.11\n",
      "| epoch 2 |  iter 6041 / 9295 | time 489[s] | loss 2.09\n",
      "| epoch 2 |  iter 6061 / 9295 | time 489[s] | loss 2.09\n",
      "| epoch 2 |  iter 6081 / 9295 | time 490[s] | loss 2.05\n",
      "| epoch 2 |  iter 6101 / 9295 | time 491[s] | loss 2.06\n",
      "| epoch 2 |  iter 6121 / 9295 | time 491[s] | loss 2.06\n",
      "| epoch 2 |  iter 6141 / 9295 | time 492[s] | loss 2.05\n",
      "| epoch 2 |  iter 6161 / 9295 | time 493[s] | loss 2.06\n",
      "| epoch 2 |  iter 6181 / 9295 | time 493[s] | loss 2.05\n",
      "| epoch 2 |  iter 6201 / 9295 | time 494[s] | loss 2.06\n",
      "| epoch 2 |  iter 6221 / 9295 | time 495[s] | loss 2.09\n",
      "| epoch 2 |  iter 6241 / 9295 | time 495[s] | loss 2.05\n",
      "| epoch 2 |  iter 6261 / 9295 | time 496[s] | loss 2.03\n",
      "| epoch 2 |  iter 6281 / 9295 | time 496[s] | loss 2.01\n",
      "| epoch 2 |  iter 6301 / 9295 | time 497[s] | loss 2.05\n",
      "| epoch 2 |  iter 6321 / 9295 | time 498[s] | loss 2.06\n",
      "| epoch 2 |  iter 6341 / 9295 | time 498[s] | loss 2.07\n",
      "| epoch 2 |  iter 6361 / 9295 | time 499[s] | loss 2.07\n",
      "| epoch 2 |  iter 6381 / 9295 | time 500[s] | loss 2.04\n",
      "| epoch 2 |  iter 6401 / 9295 | time 500[s] | loss 2.07\n",
      "| epoch 2 |  iter 6421 / 9295 | time 501[s] | loss 2.03\n",
      "| epoch 2 |  iter 6441 / 9295 | time 502[s] | loss 2.04\n",
      "| epoch 2 |  iter 6461 / 9295 | time 502[s] | loss 2.06\n",
      "| epoch 2 |  iter 6481 / 9295 | time 503[s] | loss 2.08\n",
      "| epoch 2 |  iter 6501 / 9295 | time 503[s] | loss 2.05\n",
      "| epoch 2 |  iter 6521 / 9295 | time 504[s] | loss 2.09\n",
      "| epoch 2 |  iter 6541 / 9295 | time 505[s] | loss 2.06\n",
      "| epoch 2 |  iter 6561 / 9295 | time 505[s] | loss 2.06\n",
      "| epoch 2 |  iter 6581 / 9295 | time 506[s] | loss 2.05\n",
      "| epoch 2 |  iter 6601 / 9295 | time 507[s] | loss 2.07\n",
      "| epoch 2 |  iter 6621 / 9295 | time 507[s] | loss 2.03\n",
      "| epoch 2 |  iter 6641 / 9295 | time 508[s] | loss 2.04\n",
      "| epoch 2 |  iter 6661 / 9295 | time 509[s] | loss 2.00\n",
      "| epoch 2 |  iter 6681 / 9295 | time 509[s] | loss 2.06\n",
      "| epoch 2 |  iter 6701 / 9295 | time 510[s] | loss 2.06\n",
      "| epoch 2 |  iter 6721 / 9295 | time 510[s] | loss 2.05\n",
      "| epoch 2 |  iter 6741 / 9295 | time 511[s] | loss 2.07\n",
      "| epoch 2 |  iter 6761 / 9295 | time 512[s] | loss 2.02\n",
      "| epoch 2 |  iter 6781 / 9295 | time 512[s] | loss 2.07\n",
      "| epoch 2 |  iter 6801 / 9295 | time 513[s] | loss 2.05\n",
      "| epoch 2 |  iter 6821 / 9295 | time 514[s] | loss 2.06\n",
      "| epoch 2 |  iter 6841 / 9295 | time 514[s] | loss 2.04\n",
      "| epoch 2 |  iter 6861 / 9295 | time 515[s] | loss 2.06\n",
      "| epoch 2 |  iter 6881 / 9295 | time 516[s] | loss 2.05\n",
      "| epoch 2 |  iter 6901 / 9295 | time 516[s] | loss 2.03\n",
      "| epoch 2 |  iter 6921 / 9295 | time 517[s] | loss 2.05\n",
      "| epoch 2 |  iter 6941 / 9295 | time 517[s] | loss 2.06\n",
      "| epoch 2 |  iter 6961 / 9295 | time 518[s] | loss 2.06\n",
      "| epoch 2 |  iter 6981 / 9295 | time 519[s] | loss 2.06\n",
      "| epoch 2 |  iter 7001 / 9295 | time 519[s] | loss 2.06\n",
      "| epoch 2 |  iter 7021 / 9295 | time 520[s] | loss 2.06\n",
      "| epoch 2 |  iter 7041 / 9295 | time 521[s] | loss 2.01\n",
      "| epoch 2 |  iter 7061 / 9295 | time 521[s] | loss 2.02\n",
      "| epoch 2 |  iter 7081 / 9295 | time 522[s] | loss 2.06\n",
      "| epoch 2 |  iter 7101 / 9295 | time 523[s] | loss 2.05\n",
      "| epoch 2 |  iter 7121 / 9295 | time 523[s] | loss 2.04\n",
      "| epoch 2 |  iter 7141 / 9295 | time 524[s] | loss 2.08\n",
      "| epoch 2 |  iter 7161 / 9295 | time 524[s] | loss 2.07\n",
      "| epoch 2 |  iter 7181 / 9295 | time 525[s] | loss 2.05\n",
      "| epoch 2 |  iter 7201 / 9295 | time 526[s] | loss 2.04\n",
      "| epoch 2 |  iter 7221 / 9295 | time 526[s] | loss 2.07\n",
      "| epoch 2 |  iter 7241 / 9295 | time 527[s] | loss 2.04\n",
      "| epoch 2 |  iter 7261 / 9295 | time 528[s] | loss 2.04\n",
      "| epoch 2 |  iter 7281 / 9295 | time 528[s] | loss 2.04\n",
      "| epoch 2 |  iter 7301 / 9295 | time 529[s] | loss 2.07\n",
      "| epoch 2 |  iter 7321 / 9295 | time 530[s] | loss 2.03\n",
      "| epoch 2 |  iter 7341 / 9295 | time 530[s] | loss 2.05\n",
      "| epoch 2 |  iter 7361 / 9295 | time 531[s] | loss 2.04\n",
      "| epoch 2 |  iter 7381 / 9295 | time 531[s] | loss 2.01\n",
      "| epoch 2 |  iter 7401 / 9295 | time 532[s] | loss 2.08\n",
      "| epoch 2 |  iter 7421 / 9295 | time 533[s] | loss 2.06\n",
      "| epoch 2 |  iter 7441 / 9295 | time 533[s] | loss 2.05\n",
      "| epoch 2 |  iter 7461 / 9295 | time 534[s] | loss 2.03\n",
      "| epoch 2 |  iter 7481 / 9295 | time 535[s] | loss 2.04\n",
      "| epoch 2 |  iter 7501 / 9295 | time 535[s] | loss 2.02\n",
      "| epoch 2 |  iter 7521 / 9295 | time 536[s] | loss 2.03\n",
      "| epoch 2 |  iter 7541 / 9295 | time 537[s] | loss 2.05\n",
      "| epoch 2 |  iter 7561 / 9295 | time 537[s] | loss 2.04\n",
      "| epoch 2 |  iter 7581 / 9295 | time 538[s] | loss 2.05\n",
      "| epoch 2 |  iter 7601 / 9295 | time 538[s] | loss 2.04\n",
      "| epoch 2 |  iter 7621 / 9295 | time 539[s] | loss 2.00\n",
      "| epoch 2 |  iter 7641 / 9295 | time 540[s] | loss 2.05\n",
      "| epoch 2 |  iter 7661 / 9295 | time 540[s] | loss 2.05\n",
      "| epoch 2 |  iter 7681 / 9295 | time 541[s] | loss 2.02\n",
      "| epoch 2 |  iter 7701 / 9295 | time 542[s] | loss 1.99\n",
      "| epoch 2 |  iter 7721 / 9295 | time 542[s] | loss 2.00\n",
      "| epoch 2 |  iter 7741 / 9295 | time 543[s] | loss 2.03\n",
      "| epoch 2 |  iter 7761 / 9295 | time 543[s] | loss 2.06\n",
      "| epoch 2 |  iter 7781 / 9295 | time 544[s] | loss 2.05\n",
      "| epoch 2 |  iter 7801 / 9295 | time 545[s] | loss 2.05\n",
      "| epoch 2 |  iter 7821 / 9295 | time 545[s] | loss 2.04\n",
      "| epoch 2 |  iter 7841 / 9295 | time 546[s] | loss 2.02\n",
      "| epoch 2 |  iter 7861 / 9295 | time 547[s] | loss 2.04\n",
      "| epoch 2 |  iter 7881 / 9295 | time 547[s] | loss 2.06\n",
      "| epoch 2 |  iter 7901 / 9295 | time 548[s] | loss 2.05\n",
      "| epoch 2 |  iter 7921 / 9295 | time 549[s] | loss 2.03\n",
      "| epoch 2 |  iter 7941 / 9295 | time 549[s] | loss 2.06\n",
      "| epoch 2 |  iter 7961 / 9295 | time 550[s] | loss 2.04\n",
      "| epoch 2 |  iter 7981 / 9295 | time 550[s] | loss 2.01\n",
      "| epoch 2 |  iter 8001 / 9295 | time 551[s] | loss 1.97\n",
      "| epoch 2 |  iter 8021 / 9295 | time 552[s] | loss 2.04\n",
      "| epoch 2 |  iter 8041 / 9295 | time 552[s] | loss 2.07\n",
      "| epoch 2 |  iter 8061 / 9295 | time 553[s] | loss 2.02\n",
      "| epoch 2 |  iter 8081 / 9295 | time 554[s] | loss 2.05\n",
      "| epoch 2 |  iter 8101 / 9295 | time 554[s] | loss 2.04\n",
      "| epoch 2 |  iter 8121 / 9295 | time 555[s] | loss 2.02\n",
      "| epoch 2 |  iter 8141 / 9295 | time 556[s] | loss 2.01\n",
      "| epoch 2 |  iter 8161 / 9295 | time 556[s] | loss 2.04\n",
      "| epoch 2 |  iter 8181 / 9295 | time 557[s] | loss 2.01\n",
      "| epoch 2 |  iter 8201 / 9295 | time 557[s] | loss 2.02\n",
      "| epoch 2 |  iter 8221 / 9295 | time 558[s] | loss 2.08\n",
      "| epoch 2 |  iter 8241 / 9295 | time 559[s] | loss 2.01\n",
      "| epoch 2 |  iter 8261 / 9295 | time 559[s] | loss 2.04\n",
      "| epoch 2 |  iter 8281 / 9295 | time 560[s] | loss 2.05\n",
      "| epoch 2 |  iter 8301 / 9295 | time 561[s] | loss 2.04\n",
      "| epoch 2 |  iter 8321 / 9295 | time 561[s] | loss 2.01\n",
      "| epoch 2 |  iter 8341 / 9295 | time 562[s] | loss 1.99\n",
      "| epoch 2 |  iter 8361 / 9295 | time 563[s] | loss 2.03\n",
      "| epoch 2 |  iter 8381 / 9295 | time 563[s] | loss 2.02\n",
      "| epoch 2 |  iter 8401 / 9295 | time 564[s] | loss 2.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 8421 / 9295 | time 564[s] | loss 2.05\n",
      "| epoch 2 |  iter 8441 / 9295 | time 565[s] | loss 2.08\n",
      "| epoch 2 |  iter 8461 / 9295 | time 566[s] | loss 2.02\n",
      "| epoch 2 |  iter 8481 / 9295 | time 566[s] | loss 1.99\n",
      "| epoch 2 |  iter 8501 / 9295 | time 567[s] | loss 2.05\n",
      "| epoch 2 |  iter 8521 / 9295 | time 568[s] | loss 2.00\n",
      "| epoch 2 |  iter 8541 / 9295 | time 568[s] | loss 2.00\n",
      "| epoch 2 |  iter 8561 / 9295 | time 569[s] | loss 1.99\n",
      "| epoch 2 |  iter 8581 / 9295 | time 570[s] | loss 2.00\n",
      "| epoch 2 |  iter 8601 / 9295 | time 570[s] | loss 2.04\n",
      "| epoch 2 |  iter 8621 / 9295 | time 571[s] | loss 2.07\n",
      "| epoch 2 |  iter 8641 / 9295 | time 571[s] | loss 2.03\n",
      "| epoch 2 |  iter 8661 / 9295 | time 572[s] | loss 2.00\n",
      "| epoch 2 |  iter 8681 / 9295 | time 573[s] | loss 2.00\n",
      "| epoch 2 |  iter 8701 / 9295 | time 573[s] | loss 2.02\n",
      "| epoch 2 |  iter 8721 / 9295 | time 574[s] | loss 1.98\n",
      "| epoch 2 |  iter 8741 / 9295 | time 575[s] | loss 2.01\n",
      "| epoch 2 |  iter 8761 / 9295 | time 575[s] | loss 2.06\n",
      "| epoch 2 |  iter 8781 / 9295 | time 576[s] | loss 2.02\n",
      "| epoch 2 |  iter 8801 / 9295 | time 577[s] | loss 2.07\n",
      "| epoch 2 |  iter 8821 / 9295 | time 577[s] | loss 2.01\n",
      "| epoch 2 |  iter 8841 / 9295 | time 578[s] | loss 2.08\n",
      "| epoch 2 |  iter 8861 / 9295 | time 578[s] | loss 2.01\n",
      "| epoch 2 |  iter 8881 / 9295 | time 579[s] | loss 2.03\n",
      "| epoch 2 |  iter 8901 / 9295 | time 580[s] | loss 2.01\n",
      "| epoch 2 |  iter 8921 / 9295 | time 580[s] | loss 2.01\n",
      "| epoch 2 |  iter 8941 / 9295 | time 581[s] | loss 1.99\n",
      "| epoch 2 |  iter 8961 / 9295 | time 582[s] | loss 2.02\n",
      "| epoch 2 |  iter 8981 / 9295 | time 582[s] | loss 2.02\n",
      "| epoch 2 |  iter 9001 / 9295 | time 583[s] | loss 2.03\n",
      "| epoch 2 |  iter 9021 / 9295 | time 584[s] | loss 2.06\n",
      "| epoch 2 |  iter 9041 / 9295 | time 584[s] | loss 2.04\n",
      "| epoch 2 |  iter 9061 / 9295 | time 585[s] | loss 1.99\n",
      "| epoch 2 |  iter 9081 / 9295 | time 585[s] | loss 2.03\n",
      "| epoch 2 |  iter 9101 / 9295 | time 586[s] | loss 2.05\n",
      "| epoch 2 |  iter 9121 / 9295 | time 587[s] | loss 2.01\n",
      "| epoch 2 |  iter 9141 / 9295 | time 587[s] | loss 2.02\n",
      "| epoch 2 |  iter 9161 / 9295 | time 588[s] | loss 2.03\n",
      "| epoch 2 |  iter 9181 / 9295 | time 589[s] | loss 2.05\n",
      "| epoch 2 |  iter 9201 / 9295 | time 589[s] | loss 2.02\n",
      "| epoch 2 |  iter 9221 / 9295 | time 590[s] | loss 2.00\n",
      "| epoch 2 |  iter 9241 / 9295 | time 591[s] | loss 2.04\n",
      "| epoch 2 |  iter 9261 / 9295 | time 591[s] | loss 2.01\n",
      "| epoch 2 |  iter 9281 / 9295 | time 592[s] | loss 2.07\n",
      "| epoch 3 |  iter 1 / 9295 | time 592[s] | loss 2.00\n",
      "| epoch 3 |  iter 21 / 9295 | time 593[s] | loss 1.95\n",
      "| epoch 3 |  iter 41 / 9295 | time 594[s] | loss 1.94\n",
      "| epoch 3 |  iter 61 / 9295 | time 594[s] | loss 1.96\n",
      "| epoch 3 |  iter 81 / 9295 | time 595[s] | loss 1.97\n",
      "| epoch 3 |  iter 101 / 9295 | time 596[s] | loss 1.95\n",
      "| epoch 3 |  iter 121 / 9295 | time 596[s] | loss 1.96\n",
      "| epoch 3 |  iter 141 / 9295 | time 597[s] | loss 1.92\n",
      "| epoch 3 |  iter 161 / 9295 | time 597[s] | loss 1.96\n",
      "| epoch 3 |  iter 181 / 9295 | time 598[s] | loss 1.95\n",
      "| epoch 3 |  iter 201 / 9295 | time 599[s] | loss 1.96\n",
      "| epoch 3 |  iter 221 / 9295 | time 599[s] | loss 1.96\n",
      "| epoch 3 |  iter 241 / 9295 | time 600[s] | loss 1.97\n",
      "| epoch 3 |  iter 261 / 9295 | time 601[s] | loss 1.98\n",
      "| epoch 3 |  iter 281 / 9295 | time 601[s] | loss 1.96\n",
      "| epoch 3 |  iter 301 / 9295 | time 602[s] | loss 1.94\n",
      "| epoch 3 |  iter 321 / 9295 | time 603[s] | loss 1.92\n",
      "| epoch 3 |  iter 341 / 9295 | time 603[s] | loss 1.92\n",
      "| epoch 3 |  iter 361 / 9295 | time 604[s] | loss 1.93\n",
      "| epoch 3 |  iter 381 / 9295 | time 604[s] | loss 1.98\n",
      "| epoch 3 |  iter 401 / 9295 | time 605[s] | loss 1.98\n",
      "| epoch 3 |  iter 421 / 9295 | time 606[s] | loss 1.96\n",
      "| epoch 3 |  iter 441 / 9295 | time 606[s] | loss 1.93\n",
      "| epoch 3 |  iter 461 / 9295 | time 607[s] | loss 1.94\n",
      "| epoch 3 |  iter 481 / 9295 | time 608[s] | loss 1.94\n",
      "| epoch 3 |  iter 501 / 9295 | time 608[s] | loss 1.95\n",
      "| epoch 3 |  iter 521 / 9295 | time 609[s] | loss 1.95\n",
      "| epoch 3 |  iter 541 / 9295 | time 609[s] | loss 1.91\n",
      "| epoch 3 |  iter 561 / 9295 | time 610[s] | loss 1.95\n",
      "| epoch 3 |  iter 581 / 9295 | time 611[s] | loss 1.97\n",
      "| epoch 3 |  iter 601 / 9295 | time 611[s] | loss 1.96\n",
      "| epoch 3 |  iter 621 / 9295 | time 612[s] | loss 1.96\n",
      "| epoch 3 |  iter 641 / 9295 | time 613[s] | loss 1.99\n",
      "| epoch 3 |  iter 661 / 9295 | time 613[s] | loss 1.93\n",
      "| epoch 3 |  iter 681 / 9295 | time 614[s] | loss 1.93\n",
      "| epoch 3 |  iter 701 / 9295 | time 615[s] | loss 1.95\n",
      "| epoch 3 |  iter 721 / 9295 | time 615[s] | loss 2.00\n",
      "| epoch 3 |  iter 741 / 9295 | time 616[s] | loss 1.98\n",
      "| epoch 3 |  iter 761 / 9295 | time 616[s] | loss 1.96\n",
      "| epoch 3 |  iter 781 / 9295 | time 617[s] | loss 1.91\n",
      "| epoch 3 |  iter 801 / 9295 | time 618[s] | loss 1.96\n",
      "| epoch 3 |  iter 821 / 9295 | time 618[s] | loss 1.94\n",
      "| epoch 3 |  iter 841 / 9295 | time 619[s] | loss 1.97\n",
      "| epoch 3 |  iter 861 / 9295 | time 620[s] | loss 1.97\n",
      "| epoch 3 |  iter 881 / 9295 | time 620[s] | loss 1.92\n",
      "| epoch 3 |  iter 901 / 9295 | time 621[s] | loss 1.97\n",
      "| epoch 3 |  iter 921 / 9295 | time 622[s] | loss 1.99\n",
      "| epoch 3 |  iter 941 / 9295 | time 622[s] | loss 1.95\n",
      "| epoch 3 |  iter 961 / 9295 | time 623[s] | loss 1.95\n",
      "| epoch 3 |  iter 981 / 9295 | time 623[s] | loss 1.93\n",
      "| epoch 3 |  iter 1001 / 9295 | time 624[s] | loss 1.97\n",
      "| epoch 3 |  iter 1021 / 9295 | time 625[s] | loss 1.97\n",
      "| epoch 3 |  iter 1041 / 9295 | time 625[s] | loss 1.95\n",
      "| epoch 3 |  iter 1061 / 9295 | time 626[s] | loss 1.97\n",
      "| epoch 3 |  iter 1081 / 9295 | time 627[s] | loss 1.94\n",
      "| epoch 3 |  iter 1101 / 9295 | time 627[s] | loss 1.94\n",
      "| epoch 3 |  iter 1121 / 9295 | time 628[s] | loss 1.92\n",
      "| epoch 3 |  iter 1141 / 9295 | time 628[s] | loss 1.93\n",
      "| epoch 3 |  iter 1161 / 9295 | time 629[s] | loss 1.93\n",
      "| epoch 3 |  iter 1181 / 9295 | time 630[s] | loss 1.94\n",
      "| epoch 3 |  iter 1201 / 9295 | time 630[s] | loss 1.94\n",
      "| epoch 3 |  iter 1221 / 9295 | time 631[s] | loss 1.94\n",
      "| epoch 3 |  iter 1241 / 9295 | time 632[s] | loss 1.88\n",
      "| epoch 3 |  iter 1261 / 9295 | time 632[s] | loss 1.96\n",
      "| epoch 3 |  iter 1281 / 9295 | time 633[s] | loss 1.93\n",
      "| epoch 3 |  iter 1301 / 9295 | time 634[s] | loss 1.94\n",
      "| epoch 3 |  iter 1321 / 9295 | time 634[s] | loss 1.97\n",
      "| epoch 3 |  iter 1341 / 9295 | time 635[s] | loss 1.93\n",
      "| epoch 3 |  iter 1361 / 9295 | time 635[s] | loss 1.93\n",
      "| epoch 3 |  iter 1381 / 9295 | time 636[s] | loss 1.97\n",
      "| epoch 3 |  iter 1401 / 9295 | time 637[s] | loss 1.90\n",
      "| epoch 3 |  iter 1421 / 9295 | time 637[s] | loss 1.98\n",
      "| epoch 3 |  iter 1441 / 9295 | time 638[s] | loss 1.99\n",
      "| epoch 3 |  iter 1461 / 9295 | time 639[s] | loss 1.92\n",
      "| epoch 3 |  iter 1481 / 9295 | time 639[s] | loss 1.92\n",
      "| epoch 3 |  iter 1501 / 9295 | time 640[s] | loss 1.92\n",
      "| epoch 3 |  iter 1521 / 9295 | time 641[s] | loss 1.91\n",
      "| epoch 3 |  iter 1541 / 9295 | time 641[s] | loss 1.95\n",
      "| epoch 3 |  iter 1561 / 9295 | time 642[s] | loss 1.94\n",
      "| epoch 3 |  iter 1581 / 9295 | time 642[s] | loss 1.95\n",
      "| epoch 3 |  iter 1601 / 9295 | time 643[s] | loss 1.94\n",
      "| epoch 3 |  iter 1621 / 9295 | time 644[s] | loss 1.97\n",
      "| epoch 3 |  iter 1641 / 9295 | time 644[s] | loss 1.94\n",
      "| epoch 3 |  iter 1661 / 9295 | time 645[s] | loss 1.97\n",
      "| epoch 3 |  iter 1681 / 9295 | time 646[s] | loss 1.95\n",
      "| epoch 3 |  iter 1701 / 9295 | time 646[s] | loss 1.93\n",
      "| epoch 3 |  iter 1721 / 9295 | time 647[s] | loss 1.94\n",
      "| epoch 3 |  iter 1741 / 9295 | time 648[s] | loss 1.92\n",
      "| epoch 3 |  iter 1761 / 9295 | time 648[s] | loss 1.96\n",
      "| epoch 3 |  iter 1781 / 9295 | time 649[s] | loss 1.98\n",
      "| epoch 3 |  iter 1801 / 9295 | time 649[s] | loss 1.99\n",
      "| epoch 3 |  iter 1821 / 9295 | time 650[s] | loss 1.94\n",
      "| epoch 3 |  iter 1841 / 9295 | time 651[s] | loss 1.98\n",
      "| epoch 3 |  iter 1861 / 9295 | time 651[s] | loss 1.99\n",
      "| epoch 3 |  iter 1881 / 9295 | time 652[s] | loss 1.94\n",
      "| epoch 3 |  iter 1901 / 9295 | time 653[s] | loss 1.94\n",
      "| epoch 3 |  iter 1921 / 9295 | time 653[s] | loss 1.95\n",
      "| epoch 3 |  iter 1941 / 9295 | time 654[s] | loss 1.97\n",
      "| epoch 3 |  iter 1961 / 9295 | time 655[s] | loss 1.92\n",
      "| epoch 3 |  iter 1981 / 9295 | time 655[s] | loss 1.97\n",
      "| epoch 3 |  iter 2001 / 9295 | time 656[s] | loss 1.96\n",
      "| epoch 3 |  iter 2021 / 9295 | time 656[s] | loss 1.96\n",
      "| epoch 3 |  iter 2041 / 9295 | time 657[s] | loss 1.91\n",
      "| epoch 3 |  iter 2061 / 9295 | time 658[s] | loss 1.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 3 |  iter 2081 / 9295 | time 658[s] | loss 1.99\n",
      "| epoch 3 |  iter 2101 / 9295 | time 659[s] | loss 1.92\n",
      "| epoch 3 |  iter 2121 / 9295 | time 660[s] | loss 1.94\n",
      "| epoch 3 |  iter 2141 / 9295 | time 660[s] | loss 1.96\n",
      "| epoch 3 |  iter 2161 / 9295 | time 661[s] | loss 1.94\n",
      "| epoch 3 |  iter 2181 / 9295 | time 662[s] | loss 1.96\n",
      "| epoch 3 |  iter 2201 / 9295 | time 662[s] | loss 1.93\n",
      "| epoch 3 |  iter 2221 / 9295 | time 667[s] | loss 1.94\n",
      "| epoch 3 |  iter 2241 / 9295 | time 668[s] | loss 1.90\n",
      "| epoch 3 |  iter 2261 / 9295 | time 668[s] | loss 1.97\n",
      "| epoch 3 |  iter 2281 / 9295 | time 669[s] | loss 1.95\n",
      "| epoch 3 |  iter 2301 / 9295 | time 670[s] | loss 1.92\n",
      "| epoch 3 |  iter 2321 / 9295 | time 670[s] | loss 1.96\n",
      "| epoch 3 |  iter 2341 / 9295 | time 671[s] | loss 1.99\n",
      "| epoch 3 |  iter 2361 / 9295 | time 672[s] | loss 1.94\n",
      "| epoch 3 |  iter 2381 / 9295 | time 672[s] | loss 1.94\n",
      "| epoch 3 |  iter 2401 / 9295 | time 673[s] | loss 1.95\n",
      "| epoch 3 |  iter 2421 / 9295 | time 674[s] | loss 1.93\n",
      "| epoch 3 |  iter 2441 / 9295 | time 674[s] | loss 1.96\n",
      "| epoch 3 |  iter 2461 / 9295 | time 675[s] | loss 1.95\n",
      "| epoch 3 |  iter 2481 / 9295 | time 675[s] | loss 1.93\n",
      "| epoch 3 |  iter 2501 / 9295 | time 676[s] | loss 1.96\n",
      "| epoch 3 |  iter 2521 / 9295 | time 677[s] | loss 1.92\n",
      "| epoch 3 |  iter 2541 / 9295 | time 677[s] | loss 1.92\n",
      "| epoch 3 |  iter 2561 / 9295 | time 678[s] | loss 1.96\n",
      "| epoch 3 |  iter 2581 / 9295 | time 679[s] | loss 1.94\n",
      "| epoch 3 |  iter 2601 / 9295 | time 679[s] | loss 1.93\n",
      "| epoch 3 |  iter 2621 / 9295 | time 680[s] | loss 1.94\n",
      "| epoch 3 |  iter 2641 / 9295 | time 681[s] | loss 1.93\n",
      "| epoch 3 |  iter 2661 / 9295 | time 681[s] | loss 1.92\n",
      "| epoch 3 |  iter 2681 / 9295 | time 682[s] | loss 1.95\n",
      "| epoch 3 |  iter 2701 / 9295 | time 683[s] | loss 1.92\n",
      "| epoch 3 |  iter 2721 / 9295 | time 684[s] | loss 1.94\n",
      "| epoch 3 |  iter 2741 / 9295 | time 684[s] | loss 1.96\n",
      "| epoch 3 |  iter 2761 / 9295 | time 685[s] | loss 1.95\n",
      "| epoch 3 |  iter 2781 / 9295 | time 686[s] | loss 1.97\n",
      "| epoch 3 |  iter 2801 / 9295 | time 686[s] | loss 1.86\n",
      "| epoch 3 |  iter 2821 / 9295 | time 687[s] | loss 1.92\n",
      "| epoch 3 |  iter 2841 / 9295 | time 688[s] | loss 1.93\n",
      "| epoch 3 |  iter 2861 / 9295 | time 688[s] | loss 1.92\n",
      "| epoch 3 |  iter 2881 / 9295 | time 689[s] | loss 1.97\n",
      "| epoch 3 |  iter 2901 / 9295 | time 689[s] | loss 1.92\n",
      "| epoch 3 |  iter 2921 / 9295 | time 690[s] | loss 1.94\n",
      "| epoch 3 |  iter 2941 / 9295 | time 691[s] | loss 1.97\n",
      "| epoch 3 |  iter 2961 / 9295 | time 691[s] | loss 1.95\n",
      "| epoch 3 |  iter 2981 / 9295 | time 692[s] | loss 1.94\n",
      "| epoch 3 |  iter 3001 / 9295 | time 693[s] | loss 1.95\n",
      "| epoch 3 |  iter 3021 / 9295 | time 693[s] | loss 1.88\n",
      "| epoch 3 |  iter 3041 / 9295 | time 694[s] | loss 1.93\n",
      "| epoch 3 |  iter 3061 / 9295 | time 694[s] | loss 1.98\n",
      "| epoch 3 |  iter 3081 / 9295 | time 695[s] | loss 1.96\n",
      "| epoch 3 |  iter 3101 / 9295 | time 696[s] | loss 1.95\n",
      "| epoch 3 |  iter 3121 / 9295 | time 696[s] | loss 1.93\n",
      "| epoch 3 |  iter 3141 / 9295 | time 697[s] | loss 1.94\n",
      "| epoch 3 |  iter 3161 / 9295 | time 698[s] | loss 1.94\n",
      "| epoch 3 |  iter 3181 / 9295 | time 698[s] | loss 1.91\n",
      "| epoch 3 |  iter 3201 / 9295 | time 699[s] | loss 1.91\n",
      "| epoch 3 |  iter 3221 / 9295 | time 700[s] | loss 1.97\n",
      "| epoch 3 |  iter 3241 / 9295 | time 700[s] | loss 1.94\n",
      "| epoch 3 |  iter 3261 / 9295 | time 701[s] | loss 1.94\n",
      "| epoch 3 |  iter 3281 / 9295 | time 702[s] | loss 1.93\n",
      "| epoch 3 |  iter 3301 / 9295 | time 702[s] | loss 1.97\n",
      "| epoch 3 |  iter 3321 / 9295 | time 703[s] | loss 1.89\n",
      "| epoch 3 |  iter 3341 / 9295 | time 704[s] | loss 1.90\n",
      "| epoch 3 |  iter 3361 / 9295 | time 704[s] | loss 1.90\n",
      "| epoch 3 |  iter 3381 / 9295 | time 705[s] | loss 1.91\n",
      "| epoch 3 |  iter 3401 / 9295 | time 705[s] | loss 1.94\n",
      "| epoch 3 |  iter 3421 / 9295 | time 706[s] | loss 1.98\n",
      "| epoch 3 |  iter 3441 / 9295 | time 707[s] | loss 1.90\n",
      "| epoch 3 |  iter 3461 / 9295 | time 707[s] | loss 1.92\n",
      "| epoch 3 |  iter 3481 / 9295 | time 708[s] | loss 1.92\n",
      "| epoch 3 |  iter 3501 / 9295 | time 709[s] | loss 1.94\n",
      "| epoch 3 |  iter 3521 / 9295 | time 709[s] | loss 1.93\n",
      "| epoch 3 |  iter 3541 / 9295 | time 710[s] | loss 1.94\n",
      "| epoch 3 |  iter 3561 / 9295 | time 710[s] | loss 1.93\n",
      "| epoch 3 |  iter 3581 / 9295 | time 711[s] | loss 1.95\n",
      "| epoch 3 |  iter 3601 / 9295 | time 712[s] | loss 1.88\n",
      "| epoch 3 |  iter 3621 / 9295 | time 712[s] | loss 1.97\n",
      "| epoch 3 |  iter 3641 / 9295 | time 713[s] | loss 1.92\n",
      "| epoch 3 |  iter 3661 / 9295 | time 714[s] | loss 1.91\n",
      "| epoch 3 |  iter 3681 / 9295 | time 714[s] | loss 1.92\n",
      "| epoch 3 |  iter 3701 / 9295 | time 715[s] | loss 1.95\n",
      "| epoch 3 |  iter 3721 / 9295 | time 716[s] | loss 1.91\n",
      "| epoch 3 |  iter 3741 / 9295 | time 716[s] | loss 1.90\n",
      "| epoch 3 |  iter 3761 / 9295 | time 717[s] | loss 1.96\n",
      "| epoch 3 |  iter 3781 / 9295 | time 717[s] | loss 1.91\n",
      "| epoch 3 |  iter 3801 / 9295 | time 718[s] | loss 1.94\n",
      "| epoch 3 |  iter 3821 / 9295 | time 719[s] | loss 1.93\n",
      "| epoch 3 |  iter 3841 / 9295 | time 719[s] | loss 1.93\n",
      "| epoch 3 |  iter 3861 / 9295 | time 720[s] | loss 1.95\n",
      "| epoch 3 |  iter 3881 / 9295 | time 721[s] | loss 1.91\n",
      "| epoch 3 |  iter 3901 / 9295 | time 721[s] | loss 1.94\n",
      "| epoch 3 |  iter 3921 / 9295 | time 722[s] | loss 1.98\n",
      "| epoch 3 |  iter 3941 / 9295 | time 723[s] | loss 1.94\n",
      "| epoch 3 |  iter 3961 / 9295 | time 723[s] | loss 1.95\n",
      "| epoch 3 |  iter 3981 / 9295 | time 724[s] | loss 1.95\n",
      "| epoch 3 |  iter 4001 / 9295 | time 724[s] | loss 1.94\n",
      "| epoch 3 |  iter 4021 / 9295 | time 725[s] | loss 1.91\n",
      "| epoch 3 |  iter 4041 / 9295 | time 726[s] | loss 1.92\n",
      "| epoch 3 |  iter 4061 / 9295 | time 726[s] | loss 1.94\n",
      "| epoch 3 |  iter 4081 / 9295 | time 727[s] | loss 1.93\n",
      "| epoch 3 |  iter 4101 / 9295 | time 728[s] | loss 1.95\n",
      "| epoch 3 |  iter 4121 / 9295 | time 728[s] | loss 1.91\n",
      "| epoch 3 |  iter 4141 / 9295 | time 729[s] | loss 1.95\n",
      "| epoch 3 |  iter 4161 / 9295 | time 730[s] | loss 1.93\n",
      "| epoch 3 |  iter 4181 / 9295 | time 730[s] | loss 1.96\n",
      "| epoch 3 |  iter 4201 / 9295 | time 731[s] | loss 1.93\n",
      "| epoch 3 |  iter 4221 / 9295 | time 731[s] | loss 1.90\n",
      "| epoch 3 |  iter 4241 / 9295 | time 732[s] | loss 1.90\n",
      "| epoch 3 |  iter 4261 / 9295 | time 733[s] | loss 1.93\n",
      "| epoch 3 |  iter 4281 / 9295 | time 733[s] | loss 1.91\n",
      "| epoch 3 |  iter 4301 / 9295 | time 734[s] | loss 1.99\n",
      "| epoch 3 |  iter 4321 / 9295 | time 735[s] | loss 1.89\n",
      "| epoch 3 |  iter 4341 / 9295 | time 735[s] | loss 1.92\n",
      "| epoch 3 |  iter 4361 / 9295 | time 736[s] | loss 1.93\n",
      "| epoch 3 |  iter 4381 / 9295 | time 737[s] | loss 1.93\n",
      "| epoch 3 |  iter 4401 / 9295 | time 737[s] | loss 1.95\n",
      "| epoch 3 |  iter 4421 / 9295 | time 738[s] | loss 1.87\n",
      "| epoch 3 |  iter 4441 / 9295 | time 738[s] | loss 1.95\n",
      "| epoch 3 |  iter 4461 / 9295 | time 739[s] | loss 1.91\n",
      "| epoch 3 |  iter 4481 / 9295 | time 740[s] | loss 1.88\n",
      "| epoch 3 |  iter 4501 / 9295 | time 740[s] | loss 1.95\n",
      "| epoch 3 |  iter 4521 / 9295 | time 741[s] | loss 1.90\n",
      "| epoch 3 |  iter 4541 / 9295 | time 742[s] | loss 1.92\n",
      "| epoch 3 |  iter 4561 / 9295 | time 742[s] | loss 1.94\n",
      "| epoch 3 |  iter 4581 / 9295 | time 743[s] | loss 1.94\n",
      "| epoch 3 |  iter 4601 / 9295 | time 744[s] | loss 1.90\n",
      "| epoch 3 |  iter 4621 / 9295 | time 744[s] | loss 1.88\n",
      "| epoch 3 |  iter 4641 / 9295 | time 745[s] | loss 1.92\n",
      "| epoch 3 |  iter 4661 / 9295 | time 745[s] | loss 1.91\n",
      "| epoch 3 |  iter 4681 / 9295 | time 746[s] | loss 1.90\n",
      "| epoch 3 |  iter 4701 / 9295 | time 747[s] | loss 1.90\n",
      "| epoch 3 |  iter 4721 / 9295 | time 747[s] | loss 1.96\n",
      "| epoch 3 |  iter 4741 / 9295 | time 748[s] | loss 1.92\n",
      "| epoch 3 |  iter 4761 / 9295 | time 749[s] | loss 1.93\n",
      "| epoch 3 |  iter 4781 / 9295 | time 749[s] | loss 1.90\n",
      "| epoch 3 |  iter 4801 / 9295 | time 750[s] | loss 1.92\n",
      "| epoch 3 |  iter 4821 / 9295 | time 750[s] | loss 1.91\n",
      "| epoch 3 |  iter 4841 / 9295 | time 751[s] | loss 1.95\n",
      "| epoch 3 |  iter 4861 / 9295 | time 752[s] | loss 1.93\n",
      "| epoch 3 |  iter 4881 / 9295 | time 752[s] | loss 1.92\n",
      "| epoch 3 |  iter 4901 / 9295 | time 753[s] | loss 1.92\n",
      "| epoch 3 |  iter 4921 / 9295 | time 754[s] | loss 1.92\n",
      "| epoch 3 |  iter 4941 / 9295 | time 754[s] | loss 1.92\n",
      "| epoch 3 |  iter 4961 / 9295 | time 755[s] | loss 1.94\n",
      "| epoch 3 |  iter 4981 / 9295 | time 756[s] | loss 1.90\n",
      "| epoch 3 |  iter 5001 / 9295 | time 756[s] | loss 1.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 3 |  iter 5021 / 9295 | time 757[s] | loss 1.96\n",
      "| epoch 3 |  iter 5041 / 9295 | time 757[s] | loss 1.93\n",
      "| epoch 3 |  iter 5061 / 9295 | time 758[s] | loss 1.91\n",
      "| epoch 3 |  iter 5081 / 9295 | time 759[s] | loss 1.91\n",
      "| epoch 3 |  iter 5101 / 9295 | time 759[s] | loss 1.91\n",
      "| epoch 3 |  iter 5121 / 9295 | time 760[s] | loss 1.93\n",
      "| epoch 3 |  iter 5141 / 9295 | time 761[s] | loss 1.93\n",
      "| epoch 3 |  iter 5161 / 9295 | time 761[s] | loss 1.91\n",
      "| epoch 3 |  iter 5181 / 9295 | time 762[s] | loss 1.90\n",
      "| epoch 3 |  iter 5201 / 9295 | time 763[s] | loss 1.93\n",
      "| epoch 3 |  iter 5221 / 9295 | time 763[s] | loss 1.91\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common import config\n",
    "import pickle\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "from cbow import CBOW\n",
    "from common.util import create_contexts_target, to_cpu, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "if config.GPU:\n",
    "    contexts, target = to_gpu(contexts), to_gpu(target)\n",
    "    \n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "tainer.plot()\n",
    "\n",
    "word_vecs = model.word_vecs\n",
    "if config.GPU:\n",
    "    word_vecs = to_cpu(word_vecs)\n",
    "params = {}\n",
    "params['word_vecs']  =word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id \n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'\n",
    "with open(pkl_file, 'wb')as f:\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ch5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, wh, b]\n",
    "        self.grads = [np.zeros_like(Wx),np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "    def forward(self, x, h_prev):\n",
    "            Wx, Wh, b = self.params\n",
    "            t = np.dot(h_prev, Wh) + np.dot(x, Wx) +b\n",
    "            h_next = np.tanh(t)\n",
    "            \n",
    "            self.cache = (x, h_prev, h_next)\n",
    "            return h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next **2)\n",
    "        db = np.sum(dt, axis = 0)\n",
    "        dwh = np.dot(h_prev.T, dt)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        dwx = np.dot(x.t, dt)\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, sateful = False):\n",
    "            self.params = [Wx, Wh, b]\n",
    "            self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "            self.layers = None\n",
    "            self.h, self.dh = None, None\n",
    "            self.sateful = stateful\n",
    "            \n",
    "    def set_state(self, h):\n",
    "            self.h = h\n",
    "            \n",
    "    def reset_state(self):\n",
    "            self.h = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, xs):\n",
    "    Wx, Wh, b = self.params\n",
    "    N, T, D = xs.shape\n",
    "    D, H = Wx.shape\n",
    "    \n",
    "    self.layers = []\n",
    "    hs = np.empty((N, T, H), dtype = 'f')\n",
    "    \n",
    "    if not self.stateful or self.h is None:\n",
    "        self.h = np.zeros((N,H), dtype = 'f')\n",
    "        \n",
    "    for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t,:], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D,H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T,D), dtype ='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "                layer = self.layers[t]\n",
    "                dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "                dx[:, t, :] = dx\n",
    "                for i, grad in enumerate(layer.grads):\n",
    "                        grads[i] += grad\n",
    "        for i ,grad in enumerate(grads):\n",
    "                self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randin\n",
    "        \n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V,D)/ 100).astype('f')\n",
    "        rnn_Wx = (rn(D,H)/ np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H,H)/ np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H,V)/ np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # すべtの重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in self.layers:\n",
    "                self.params += layer.params\n",
    "                self.grads += layer.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "def backward(self, dout = 1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "                dout = layer.backward(dout)\n",
    "        return dout\n",
    "def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocabulary size: 418\n",
      "| epoch 1 | perplexity 398.30\n",
      "| epoch 2 | perplexity 274.02\n",
      "| epoch 3 | perplexity 224.20\n",
      "| epoch 4 | perplexity 216.56\n",
      "| epoch 5 | perplexity 206.69\n",
      "| epoch 6 | perplexity 203.28\n",
      "| epoch 7 | perplexity 197.89\n",
      "| epoch 8 | perplexity 196.38\n",
      "| epoch 9 | perplexity 191.93\n",
      "| epoch 10 | perplexity 192.86\n",
      "| epoch 11 | perplexity 188.37\n",
      "| epoch 12 | perplexity 191.77\n",
      "| epoch 13 | perplexity 189.48\n",
      "| epoch 14 | perplexity 189.13\n",
      "| epoch 15 | perplexity 188.31\n",
      "| epoch 16 | perplexity 184.48\n",
      "| epoch 17 | perplexity 182.71\n",
      "| epoch 18 | perplexity 179.65\n",
      "| epoch 19 | perplexity 180.08\n",
      "| epoch 20 | perplexity 181.39\n",
      "| epoch 21 | perplexity 179.33\n",
      "| epoch 22 | perplexity 175.52\n",
      "| epoch 23 | perplexity 173.36\n",
      "| epoch 24 | perplexity 171.71\n",
      "| epoch 25 | perplexity 172.16\n",
      "| epoch 26 | perplexity 170.62\n",
      "| epoch 27 | perplexity 163.21\n",
      "| epoch 28 | perplexity 162.71\n",
      "| epoch 29 | perplexity 159.36\n",
      "| epoch 30 | perplexity 152.61\n",
      "| epoch 31 | perplexity 155.63\n",
      "| epoch 32 | perplexity 149.97\n",
      "| epoch 33 | perplexity 146.72\n",
      "| epoch 34 | perplexity 143.21\n",
      "| epoch 35 | perplexity 141.02\n",
      "| epoch 36 | perplexity 135.83\n",
      "| epoch 37 | perplexity 128.53\n",
      "| epoch 38 | perplexity 127.07\n",
      "| epoch 39 | perplexity 122.29\n",
      "| epoch 40 | perplexity 117.62\n",
      "| epoch 41 | perplexity 117.43\n",
      "| epoch 42 | perplexity 109.78\n",
      "| epoch 43 | perplexity 104.13\n",
      "| epoch 44 | perplexity 99.80\n",
      "| epoch 45 | perplexity 96.88\n",
      "| epoch 46 | perplexity 95.39\n",
      "| epoch 47 | perplexity 89.19\n",
      "| epoch 48 | perplexity 84.64\n",
      "| epoch 49 | perplexity 81.77\n",
      "| epoch 50 | perplexity 78.08\n",
      "| epoch 51 | perplexity 74.27\n",
      "| epoch 52 | perplexity 70.07\n",
      "| epoch 53 | perplexity 65.27\n",
      "| epoch 54 | perplexity 64.26\n",
      "| epoch 55 | perplexity 61.77\n",
      "| epoch 56 | perplexity 58.04\n",
      "| epoch 57 | perplexity 54.19\n",
      "| epoch 58 | perplexity 51.37\n",
      "| epoch 59 | perplexity 48.01\n",
      "| epoch 60 | perplexity 45.60\n",
      "| epoch 61 | perplexity 43.45\n",
      "| epoch 62 | perplexity 41.28\n",
      "| epoch 63 | perplexity 37.35\n",
      "| epoch 64 | perplexity 35.45\n",
      "| epoch 65 | perplexity 33.95\n",
      "| epoch 66 | perplexity 31.59\n",
      "| epoch 67 | perplexity 30.09\n",
      "| epoch 68 | perplexity 27.58\n",
      "| epoch 69 | perplexity 26.33\n",
      "| epoch 70 | perplexity 24.52\n",
      "| epoch 71 | perplexity 23.56\n",
      "| epoch 72 | perplexity 22.61\n",
      "| epoch 73 | perplexity 21.12\n",
      "| epoch 74 | perplexity 19.73\n",
      "| epoch 75 | perplexity 18.63\n",
      "| epoch 76 | perplexity 17.78\n",
      "| epoch 77 | perplexity 16.32\n",
      "| epoch 78 | perplexity 15.53\n",
      "| epoch 79 | perplexity 14.10\n",
      "| epoch 80 | perplexity 13.67\n",
      "| epoch 81 | perplexity 12.92\n",
      "| epoch 82 | perplexity 12.43\n",
      "| epoch 83 | perplexity 11.31\n",
      "| epoch 84 | perplexity 11.44\n",
      "| epoch 85 | perplexity 10.46\n",
      "| epoch 86 | perplexity 9.93\n",
      "| epoch 87 | perplexity 9.52\n",
      "| epoch 88 | perplexity 9.35\n",
      "| epoch 89 | perplexity 8.72\n",
      "| epoch 90 | perplexity 8.12\n",
      "| epoch 91 | perplexity 7.62\n",
      "| epoch 92 | perplexity 6.93\n",
      "| epoch 93 | perplexity 6.97\n",
      "| epoch 94 | perplexity 6.63\n",
      "| epoch 95 | perplexity 6.82\n",
      "| epoch 96 | perplexity 5.93\n",
      "| epoch 97 | perplexity 5.64\n",
      "| epoch 98 | perplexity 5.33\n",
      "| epoch 99 | perplexity 5.29\n",
      "| epoch 100 | perplexity 4.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5  # Truncated BPTTの展開する時間サイズ\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 学習データの読み込み（データセットを小さくする）\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "data_size = len(xs)\n",
    "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 学習時に使用する変数\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# モデルの生成\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# ミニバッチの各サンプルの読み込み開始位置を計算\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
